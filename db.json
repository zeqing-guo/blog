{"meta":{"version":1,"warehouse":"2.2.0"},"models":{"Asset":[{"_id":"themes/scribble/source/css/highlight.css","path":"css/highlight.css","modified":1,"renderable":1},{"_id":"themes/scribble/source/css/responsive.css","path":"css/responsive.css","modified":1,"renderable":1},{"_id":"themes/scribble/source/css/style.css","path":"css/style.css","modified":1,"renderable":1},{"_id":"themes/scribble/source/images/line.png","path":"images/line.png","modified":1,"renderable":1},{"_id":"themes/scribble/source/images/fav.png","path":"images/fav.png","modified":1,"renderable":1},{"_id":"themes/scribble/source/js/basics.js","path":"js/basics.js","modified":1,"renderable":1},{"_id":"themes/scribble/source/images/scribble2.png","path":"images/scribble2.png","modified":1,"renderable":1},{"_id":"themes/scribble/source/images/scribble.png","path":"images/scribble.png","modified":1,"renderable":1},{"_id":"themes/scribble/source/images/scribble3.png","path":"images/scribble3.png","modified":1,"renderable":1},{"_id":"themes/scribble/source/js/jquery.js","path":"js/jquery.js","modified":1,"renderable":1}],"Cache":[{"_id":"themes/scribble/README.md","hash":"92846992a442417a3742d2b2303de66a232277eb","modified":1502122469478},{"_id":"themes/scribble/_config.yml","hash":"cc8e4643a926cf01c57248a38056b54efbb20e4e","modified":1502122469486},{"_id":"source/about/index.md","hash":"51b5f11896c872ad1379237f7d64d9283ac31eed","modified":1502121786843},{"_id":"source/notes/index.md","hash":"ad7d93e81cb3c85f86924c0e888e1a6d69a9150e","modified":1502121786848},{"_id":"source/_posts/Hello-World.md","hash":"c4ee817e3b0d37796a5daa8baf4bcf961022666f","modified":1502121786839},{"_id":"source/_posts/Haskell踩坑总结.md","hash":"f0010e1b2017606e171deb21a95f4f82e3ae7af2","modified":1502121786834},{"_id":"source/_posts/ipfs.md","hash":"f90153c2231f253d28099073ccc643420df1e040","modified":1502122793428},{"_id":"themes/scribble/.git/config","hash":"e9cb7281a563ef61aa521a5ae6f6e2b2f8656ec0","modified":1502122469417},{"_id":"themes/scribble/.git/index","hash":"73853be55618fc36758321dbad2ed2d9143865b8","modified":1502122469822},{"_id":"themes/scribble/.git/HEAD","hash":"acbaef275e46a7f14c1ef456fff2c8bbe8c84724","modified":1502122469384},{"_id":"themes/scribble/.git/description","hash":"9635f1b7e12c045212819dd934d809ef07efa2f4","modified":1502122458584},{"_id":"themes/scribble/.git/packed-refs","hash":"ccd51dc044fb6b528e2ba92a4eaa90f776405693","modified":1502122469329},{"_id":"themes/scribble/layout/post.ejs","hash":"71bb338c45aec8b6d36e72eff7db93cbf55fc7c5","modified":1502122469663},{"_id":"themes/scribble/layout/page.ejs","hash":"94dedfa6ab8ada86eaea7a0569b9a3ee4a5601fa","modified":1502122469633},{"_id":"themes/scribble/layout/index.ejs","hash":"825638cf227a5b6b16aaf4972664f42e79896f12","modified":1502122469610},{"_id":"themes/scribble/source/css/highlight.css","hash":"7252fabc76bc9ca7fde4e3fb35e45de675d1bafc","modified":1502122469679},{"_id":"themes/scribble/source/css/responsive.css","hash":"3890cd5db871086221d58c6be1dc03bb2788821a","modified":1502122469687},{"_id":"source/notes/ostep/index.md","hash":"a5105aba97a527f53842f3d06f2dd5097b713abb","modified":1502121786852},{"_id":"themes/scribble/source/css/style.css","hash":"0b2dfcfca4f541f9b234a6d3a691c978e2c371c1","modified":1502122469695},{"_id":"themes/scribble/source/images/line.png","hash":"6dd07e452054aa94ed0e64637b593d76fde045d2","modified":1502122469707},{"_id":"themes/scribble/source/images/fav.png","hash":"829076a4714eb3b7b3d3a7b613700bda9e23d113","modified":1502122469704},{"_id":"themes/scribble/source/js/basics.js","hash":"2c5e8ff6f95526e5f5e3a5df3074ab95011ad5af","modified":1502122469721},{"_id":"themes/scribble/source/images/scribble2.png","hash":"5c25aa8ce2bed3fd03c866e11dd13df6848259a1","modified":1502122469713},{"_id":"themes/scribble/.git/hooks/applypatch-msg.sample","hash":"4de88eb95a5e93fd27e78b5fb3b5231a8d8917dd","modified":1502122458595},{"_id":"themes/scribble/source/images/scribble.png","hash":"829076a4714eb3b7b3d3a7b613700bda9e23d113","modified":1502122469710},{"_id":"themes/scribble/source/images/scribble3.png","hash":"c2420174fa4be237afeca972cc7211c50b7358d8","modified":1502122469717},{"_id":"themes/scribble/.git/hooks/post-update.sample","hash":"b614c2f63da7dca9f1db2e7ade61ef30448fc96c","modified":1502122458613},{"_id":"themes/scribble/.git/hooks/commit-msg.sample","hash":"ee1ed5aad98a435f2020b6de35c173b75d9affac","modified":1502122458603},{"_id":"themes/scribble/.git/hooks/pre-applypatch.sample","hash":"f208287c1a92525de9f5462e905a9d31de1e2d75","modified":1502122458620},{"_id":"themes/scribble/.git/hooks/pre-rebase.sample","hash":"18be3eb275c1decd3614e139f5a311b75f1b0ab8","modified":1502122458648},{"_id":"themes/scribble/.git/hooks/pre-commit.sample","hash":"36aed8976dcc08b5076844f0ec645b18bc37758f","modified":1502122458628},{"_id":"themes/scribble/.git/hooks/prepare-commit-msg.sample","hash":"2b6275eda365cad50d167fe3a387c9bc9fedd54f","modified":1502122458655},{"_id":"themes/scribble/.git/hooks/update.sample","hash":"e729cd61b27c128951d139de8e7c63d1a3758dde","modified":1502122458664},{"_id":"themes/scribble/.git/hooks/pre-push.sample","hash":"5c8518bfd1d1d3d2c1a7194994c0a16d8a313a41","modified":1502122458634},{"_id":"themes/scribble/.git/logs/HEAD","hash":"fd9554f3540fc8423673a6b356e48364d4f14447","modified":1502122469405},{"_id":"themes/scribble/layout/_partial/footer.ejs","hash":"f4703b9e0d32e2a25279a347972f6e16119c78f9","modified":1502122469518},{"_id":"themes/scribble/layout/_partial/disqus.ejs","hash":"78c590eb599ab33895f355fdb00449065cad7b50","modified":1502122469495},{"_id":"themes/scribble/layout/_partial/ga.ejs","hash":"7cdc384fe8cba69dca26bce0b106dae5b8518a19","modified":1502122469526},{"_id":"themes/scribble/.git/info/exclude","hash":"c879df015d97615050afa7b9641e3352a1e701ac","modified":1502122458670},{"_id":"themes/scribble/layout/_partial/header.ejs","hash":"e3a65048e8406fc2bfbd7fe624898e3a6792a365","modified":1502122469579},{"_id":"themes/scribble/layout/_partial/links.ejs","hash":"7dc836119faf464c4653296154041a14d3e8a324","modified":1502122469587},{"_id":"themes/scribble/layout/_partial/post_pagination.ejs","hash":"4b9b9f19ed1db7cff47ecf95da313878c9cf2ea2","modified":1502122469594},{"_id":"themes/scribble/layout/_partial/head.ejs","hash":"28cf9eb05c4a2c0d77eb76f879e874ae9ea44d51","modified":1502122469564},{"_id":"themes/scribble/layout/_partial/signoff.ejs","hash":"f954471f36d1ee17820cff70dd7f9da165e08d12","modified":1502122469603},{"_id":"themes/scribble/source/js/jquery.js","hash":"ae49e56999d82802727455f0ba83b63acd90a22b","modified":1502122469735},{"_id":"themes/scribble/.git/refs/heads/master","hash":"f29b6d329b4ff16a9e751ef3fb55a98b1333de2a","modified":1502122469395},{"_id":"themes/scribble/.git/objects/10/cba9a62fc7ba90d7cf8706c0620d3702a269c6","hash":"f204c6b8051606e7216bce75061186d8863634a4","modified":1502122468941},{"_id":"themes/scribble/.git/objects/10/d651578706e280f9734fbb28df3df2b10d132e","hash":"46d10428790654627c58674e3b2c9b280e3520a0","modified":1502122469143},{"_id":"themes/scribble/.git/objects/12/4444f575f113976293c77f4df4320fd7ccbbbc","hash":"1e2213fbdbbb6e5163d1a2e987b2461a2464933f","modified":1502122468096},{"_id":"themes/scribble/.git/objects/22/ebfc0f15577af6d0bcef8981e92d37ddea1021","hash":"651a8c7b795a29bc958cc9e8336673d33a4cb7ab","modified":1502122467934},{"_id":"themes/scribble/.git/objects/18/254ff396318467495f73b6a5f9f6234f67df78","hash":"ec33b1819444978b8813b125726faeba6f1b52ce","modified":1502122469109},{"_id":"themes/scribble/.git/objects/11/49e6832f37fe9a9dbedfc8c9b33d75e8141a4a","hash":"2b4c5aab4283ff19f47982de5107f6f143e1ce11","modified":1502122468692},{"_id":"themes/scribble/.git/objects/1f/b335a4e500c673eb89eefb532ba5cc07c949b1","hash":"c0043a4249768c6e7bbb7508a7ae8b71763bbbaa","modified":1502122468625},{"_id":"themes/scribble/.git/objects/29/7290970324a0b862c701fdfb470654111929ee","hash":"1fd94d9914aeab2988bbb81740963ff3743afb33","modified":1502122467793},{"_id":"themes/scribble/.git/objects/11/7ba0c2bbb47425cf48a1d5febf53d4b12b3915","hash":"5d790a0fd5e48f99fce9fe79a7b8bf916c788ea4","modified":1502122467897},{"_id":"themes/scribble/.git/objects/29/9a030db3cffc78dff5522efb785d4dc25fce67","hash":"0079cd76a93509dd8c12bfc82fa199cf29f20537","modified":1502122468731},{"_id":"themes/scribble/.git/objects/00/6e953102ded2db8e217e4507de3baa8bcc976d","hash":"290056f6c9b4246ca860c351e114e1c024950e56","modified":1502122468406},{"_id":"themes/scribble/.git/objects/2b/6260b717412b662777de6f142c6ddca784e748","hash":"9fbf879af79002449cfe863fa3402ab74a7ebdcc","modified":1502122468566},{"_id":"themes/scribble/.git/objects/24/0189e40dbf0fa629e6b241ce6ce8b89df8b47b","hash":"9b9931ee44241403ccc08d75c7ba4e9e19f8c462","modified":1502122468023},{"_id":"themes/scribble/.git/objects/56/8bdd1d780238054be7ed51eed7c9e7acb472ad","hash":"f6adbc1ff6ada7aa632724b09f15476ff680b690","modified":1502122469066},{"_id":"themes/scribble/.git/objects/2e/dd951e4f056734b8bfabff597e366d679e72af","hash":"c27482c14fee2ad8fca228610dc2ad1c0aed16d2","modified":1502122467844},{"_id":"themes/scribble/.git/objects/32/ec76ca88417894df0066656aacbd95feab45e7","hash":"339a6cc1634bca93b0b96f03957c552ba418cc7e","modified":1502122467972},{"_id":"themes/scribble/.git/objects/32/fe6d9799d27f5b2c8e08da35f4cb41859066ac","hash":"b30c1c71523b5611a6132e8bea8324efce564d38","modified":1502122468432},{"_id":"themes/scribble/.git/objects/4e/c1de7c04104257758eb8b7ec43ae40c9f889c2","hash":"9c7241ad7bccf64143f8299bf14269c431574c92","modified":1502122467915},{"_id":"themes/scribble/.git/objects/32/a65711e4cbb5446f7cbf5e40e8aa4d94816d40","hash":"2ba1ca6a08b3886f0a9f806b308b6ff627482261","modified":1502122468646},{"_id":"themes/scribble/.git/objects/4f/31b04b372f255d4f4ee9c36157d34c9129fccf","hash":"fcacee749285beba5aa0c02f34c4712fff4d43f2","modified":1502122469089},{"_id":"themes/scribble/.git/objects/57/01b3f36a2abe13e82c298bfb2fc1e92e70ddb6","hash":"c554118062af62be9ee45f9d748112dab530f275","modified":1502122468524},{"_id":"themes/scribble/.git/objects/82/40744ea0a99cb447d9856c3ac0e99fe6416b24","hash":"de6cc4041225f17f95e23102f0009d2f1c701093","modified":1502122468829},{"_id":"themes/scribble/.git/objects/3e/5f59ee71bf24dc1276682ba0fdb1b8cf1533c4","hash":"611ddb6d7319d32d40483aabe269734e6307c48e","modified":1502122469126},{"_id":"themes/scribble/.git/objects/38/1e983acf860da3c0376d0447897bfed4e08d65","hash":"a05f686b412848046f07a42fde07c5e5419896e2","modified":1502122468475},{"_id":"themes/scribble/.git/objects/66/2cc3581b5a61c9614cd7234b339cfda6891861","hash":"6a56cc980a68acc697aa67872bba7d9db30d6863","modified":1502122467810},{"_id":"themes/scribble/.git/objects/72/dd80db94d3fcccd3b1e9bf090f5e209363981a","hash":"c51a26117f022c6c6ce0cfe6f0aa174dbbebbc54","modified":1502122469011},{"_id":"themes/scribble/.git/objects/41/76b47465fb3f4561ce249b6383a1fab4f291cc","hash":"36fa3252f3b47009b956fa6ece9451a2547cab46","modified":1502122468805},{"_id":"themes/scribble/.git/objects/7a/fd7cc875fed205b302c0f529213d0920c31de1","hash":"550958c3762add4268157aa3cb8484f75d4a41eb","modified":1502122468041},{"_id":"themes/scribble/.git/objects/72/8f411ebbf247be516cebf21c18dd1200b426fd","hash":"f5aff6c77052b389aff2d247236aa480180e76d4","modified":1502122468605},{"_id":"themes/scribble/.git/objects/88/1c671eeb1998699a9d2da37d12ebe4dac61ba3","hash":"25b36ef72c21a0f4adca916af9f06480d41ca17d","modified":1502122468673},{"_id":"themes/scribble/.git/objects/a1/6e65761ea110f8aea0d608deaaea6e779316aa","hash":"6ca1bdb390009e45631fcd46217cfe867562c2b3","modified":1502122469197},{"_id":"themes/scribble/.git/objects/62/9122eada07a43570d33c7fa3034d9b3c885d2a","hash":"67652d80e87bef173f105c5f47ed8052e5c7cc26","modified":1502122468586},{"_id":"themes/scribble/.git/objects/9a/87eb6c07f0fdb067cb3111c9a2a64b55ae9409","hash":"67710461445d6c35062ac24d3aa5234f171344bb","modified":1502122468546},{"_id":"themes/scribble/.git/objects/92/6e02906dfd10c8207a9bbf02485baf04eb732a","hash":"a89ea6908b9d2a72192299d4cb7797911b0ae069","modified":1502122468983},{"_id":"themes/scribble/.git/objects/45/611fe8a3e2f105c462dbb3d4c21839984c7a47","hash":"12b85527e451ec130cb2aa398a1d871fb6dadba8","modified":1502122468872},{"_id":"themes/scribble/.git/objects/a3/de287adc9d9a14b80ec8a0b35e635e3e57f61f","hash":"1bbdaa4d72a01f700b96bcb49476d03c9f422de6","modified":1502122468454},{"_id":"themes/scribble/.git/objects/99/9aa7aa131a006cd30ebef1789b696b97c4dff8","hash":"b4f3c2c2dd1fe9912247f54aa88ef0dd72db418f","modified":1502122468712},{"_id":"themes/scribble/.git/objects/a3/4b8edd705cce36042230948f502910ec4ac0be","hash":"bb71c430be8757d2377599a989cc409f932ff762","modified":1502122468060},{"_id":"themes/scribble/.git/objects/c0/3a3ba22403c0a1ae6f53ddcff6ea53b92d233f","hash":"6170560f2a39397bba6061706f74b75d89d15053","modified":1502122468078},{"_id":"themes/scribble/.git/objects/c0/215396ed5cfbd4559f2141e165179f981eb712","hash":"c4aab3c9c48efed9137faa51d53077a498175aef","modified":1502122469160},{"_id":"themes/scribble/.git/objects/85/70f13718df34a3e1ada13ad5957158806fcccf","hash":"6315a4f276105d10e7c1fda27933634c937f9887","modified":1502122469178},{"_id":"themes/scribble/.git/objects/a3/fef99eba14c783126f41fb4b0556e222b694c3","hash":"acf5be37daf64bcd4eb12585fcbc44858df8fb3c","modified":1502122467991},{"_id":"themes/scribble/.git/objects/c8/b88d03ae1b247f33493978f237d2c98a26339e","hash":"6a618fe6004d7f4c608f32e5a908046475e912ad","modified":1502122467862},{"_id":"themes/scribble/.git/objects/d4/cdbe0d9ed8b4c931719a41e075d505a9bf3cdb","hash":"cbab04db5d421bd5d3feb144c8ef9072634d6809","modified":1502122468496},{"_id":"themes/scribble/.git/objects/6d/fbb34c9d2f579be53f0fdd135072c2046e3c53","hash":"6f5d03307228102b11795855c12105b609b47a6d","modified":1502122468962},{"_id":"themes/scribble/.git/objects/80/7e5f9ada8875ce3050b0d652c0442832a69aa8","hash":"875129a31927898c524189d9152240c622b15c7f","modified":1502122468895},{"_id":"themes/scribble/.git/objects/c1/eaa7ef6c2060cbbe9f42505faf6f3395337ad6","hash":"c80dc753bb2ae0e4210a2d71ab3da0fc805225d5","modified":1502122469219},{"_id":"themes/scribble/.git/objects/d5/2e89e889ee4ec4614ec919f4cd407727f10450","hash":"5013b37d09437e9b77c459b4cf28393744416151","modified":1502122468851},{"_id":"themes/scribble/.git/objects/a5/3b1213c1a42e92387d32c7824859453d6805a8","hash":"38fa6f5c0fa6409b7d6bbc46210fbdffb5e7eb3f","modified":1502122467826},{"_id":"themes/scribble/.git/objects/cc/35044b511be3ffa8a38118285d6fe4b507924b","hash":"2aa408e6f5a2a6f00aabd5a22cf9e16e824a4c33","modified":1502122467956},{"_id":"themes/scribble/.git/objects/e9/6fe8c9a4f5d0b634a3b1c19241bd4692dfde3a","hash":"70427938703c5dd797357aea6b472d160dcd4274","modified":1502122469045},{"_id":"themes/scribble/.git/objects/fb/db55734a077b7e1d0a93087193b11f2855ffb2","hash":"edfa466aa1af3ee85b7af27220518748f061c4af","modified":1502122467880},{"_id":"themes/scribble/.git/objects/e0/6b5cf5532dea911733c92b7eb45a5985d3abc7","hash":"86fdecd5c80023651fea2eae5ef22d864db4297f","modified":1502122468785},{"_id":"themes/scribble/.git/objects/f2/bb8f17e37425fabff8c4731823b1d648d211fd","hash":"0d03ca66501f7f2834d21137134d9f3e245add4e","modified":1502122468750},{"_id":"themes/scribble/.git/objects/ef/bcbfdbdcdfc076d80f47b188e4478971bdf626","hash":"5ac101fd4c4b4ce303d0d959ab5b3de65826fc3a","modified":1502122468916},{"_id":"themes/scribble/.git/logs/refs/heads/master","hash":"fd9554f3540fc8423673a6b356e48364d4f14447","modified":1502122469402},{"_id":"themes/scribble/.git/refs/remotes/origin/HEAD","hash":"d9427cda09aba1cdde5c69c2b13c905bddb0bc51","modified":1502122469340},{"_id":"themes/scribble/.git/logs/refs/remotes/origin/HEAD","hash":"fd9554f3540fc8423673a6b356e48364d4f14447","modified":1502122469376},{"_id":"public/about/index.html","hash":"3e6a9fdc79e819e3401e51e89cbaa4928a16acc0","modified":1502123471261},{"_id":"public/notes/index.html","hash":"3a229cee2319a3790cf2db629225123c32fbf53a","modified":1502123471262},{"_id":"public/2017/08/08/ipfs/index.html","hash":"7ce9345e7bc231f2d7b1083a3c93388274be485b","modified":1502123471263},{"_id":"public/2016/11/27/Haskell踩坑总结/index.html","hash":"695c47c9886f1294e5f771f988d7ea3602a462e7","modified":1502123471264},{"_id":"public/2016/09/22/Hello-World/index.html","hash":"db2a59733f7f2439d6c448351e68ea0aabe3e65c","modified":1502123471267},{"_id":"public/tags/Programming/index.html","hash":"c4f41e75db92214b9db20a120ae95d437fdaa688","modified":1502123471267},{"_id":"public/archives/index.html","hash":"7fd3b94902842fb0c9ab54ce2f702f925506d6a9","modified":1502123471267},{"_id":"public/archives/2016/index.html","hash":"4b48450196f38b042230bb15436472ecc099b3ef","modified":1502123471267},{"_id":"public/archives/2016/09/index.html","hash":"7bdf390b8c595e9eedbf4b8c1086ed80029c8e19","modified":1502123471267},{"_id":"public/archives/2016/11/index.html","hash":"c4f41e75db92214b9db20a120ae95d437fdaa688","modified":1502123471267},{"_id":"public/archives/2017/index.html","hash":"74a7715b8a1f1f221d47dec0d4fc68352162fbd1","modified":1502123471267},{"_id":"public/notes/ostep/index.html","hash":"50ed8d8f6859a7f0e30cefe377b2a3936e703654","modified":1502123471267},{"_id":"public/archives/2017/08/index.html","hash":"74a7715b8a1f1f221d47dec0d4fc68352162fbd1","modified":1502123471271},{"_id":"public/index.html","hash":"7fd3b94902842fb0c9ab54ce2f702f925506d6a9","modified":1502123471272},{"_id":"public/images/line.png","hash":"6dd07e452054aa94ed0e64637b593d76fde045d2","modified":1502123471272},{"_id":"public/images/fav.png","hash":"829076a4714eb3b7b3d3a7b613700bda9e23d113","modified":1502123471272},{"_id":"public/images/scribble.png","hash":"829076a4714eb3b7b3d3a7b613700bda9e23d113","modified":1502123471272},{"_id":"public/images/scribble3.png","hash":"c2420174fa4be237afeca972cc7211c50b7358d8","modified":1502123471273},{"_id":"public/images/scribble2.png","hash":"5c25aa8ce2bed3fd03c866e11dd13df6848259a1","modified":1502123471273},{"_id":"public/css/highlight.css","hash":"7252fabc76bc9ca7fde4e3fb35e45de675d1bafc","modified":1502123471279},{"_id":"public/js/basics.js","hash":"2c5e8ff6f95526e5f5e3a5df3074ab95011ad5af","modified":1502123471279},{"_id":"public/css/responsive.css","hash":"3890cd5db871086221d58c6be1dc03bb2788821a","modified":1502123471280},{"_id":"public/css/style.css","hash":"0b2dfcfca4f541f9b234a6d3a691c978e2c371c1","modified":1502123471280},{"_id":"public/js/jquery.js","hash":"ae49e56999d82802727455f0ba83b63acd90a22b","modified":1502123471280}],"Category":[],"Data":[],"Page":[{"title":"ABOUT","date":"2016-09-22T14:53:47.000Z","_content":"\nI'm Zeqing Guo (Chinese: 郭泽卿), a master student at [Fudan University](http://www.fudan.edu.cn). I love building things with code.\n\nYou can contact me via my email: `i at zqguo dot com`.\n\n---\n\n[Github](https://github.com/zeqing-guo)\n[Zhihu](https://www.zhihu.com/people/jason-guo-92)\n[Twitter](https://twitter.com/Jason_zq_Guo)  \n[Facebook](https://www.facebook.com/jason.guo.7777)\n","source":"about/index.md","raw":"---\ntitle: ABOUT\ndate: 2016-09-22 22:53:47\n---\n\nI'm Zeqing Guo (Chinese: 郭泽卿), a master student at [Fudan University](http://www.fudan.edu.cn). I love building things with code.\n\nYou can contact me via my email: `i at zqguo dot com`.\n\n---\n\n[Github](https://github.com/zeqing-guo)\n[Zhihu](https://www.zhihu.com/people/jason-guo-92)\n[Twitter](https://twitter.com/Jason_zq_Guo)  \n[Facebook](https://www.facebook.com/jason.guo.7777)\n","updated":"2017-08-07T16:03:06.843Z","path":"about/index.html","comments":1,"layout":"page","_id":"cj62dj3kw000020tpxtp52k1r","content":"<p>I’m Zeqing Guo (Chinese: 郭泽卿), a master student at <a href=\"http://www.fudan.edu.cn\" target=\"_blank\" rel=\"external\">Fudan University</a>. I love building things with code.</p>\n<p>You can contact me via my email: <code>i at zqguo dot com</code>.</p>\n<hr>\n<p><a href=\"https://github.com/zeqing-guo\" target=\"_blank\" rel=\"external\">Github</a><br><a href=\"https://www.zhihu.com/people/jason-guo-92\" target=\"_blank\" rel=\"external\">Zhihu</a><br><a href=\"https://twitter.com/Jason_zq_Guo\" target=\"_blank\" rel=\"external\">Twitter</a><br><a href=\"https://www.facebook.com/jason.guo.7777\" target=\"_blank\" rel=\"external\">Facebook</a></p>\n","excerpt":"","more":"<p>I’m Zeqing Guo (Chinese: 郭泽卿), a master student at <a href=\"http://www.fudan.edu.cn\">Fudan University</a>. I love building things with code.</p>\n<p>You can contact me via my email: <code>i at zqguo dot com</code>.</p>\n<hr>\n<p><a href=\"https://github.com/zeqing-guo\">Github</a><br><a href=\"https://www.zhihu.com/people/jason-guo-92\">Zhihu</a><br><a href=\"https://twitter.com/Jason_zq_Guo\">Twitter</a><br><a href=\"https://www.facebook.com/jason.guo.7777\">Facebook</a></p>\n"},{"title":"Notes","date":"2016-09-24T07:10:28.000Z","_content":"\n- Courses\n  - [Operating Systems: Three Easy Pieces](ostep)\n","source":"notes/index.md","raw":"---\ntitle: Notes\ndate: 2016-09-24 15:10:28\n---\n\n- Courses\n  - [Operating Systems: Three Easy Pieces](ostep)\n","updated":"2017-08-07T16:03:06.848Z","path":"notes/index.html","comments":1,"layout":"page","_id":"cj62dj3l8000220tp1sftdkli","content":"<ul>\n<li>Courses<ul>\n<li><a href=\"ostep\">Operating Systems: Three Easy Pieces</a></li>\n</ul>\n</li>\n</ul>\n","excerpt":"","more":"<ul>\n<li>Courses<ul>\n<li><a href=\"ostep\">Operating Systems: Three Easy Pieces</a></li>\n</ul>\n</li>\n</ul>\n"},{"title":"Operating Systems: Three Easy Pieces","date":"2016-11-03T06:35:13.000Z","mathjax":true,"_content":"\n<!-- markdown-toc start - Don't edit this section. Run M-x markdown-toc-generate-toc again -->\n**Table of Contents**\n\n- [Virtualization](#virtualization)\n    - [The Abstraction: The Process](#the-abstraction-the-process)\n    - [CPU Virtualization (Scheduling Policies)](#cpu-virtualization-scheduling-policies)\n        - [Workload Assumptions](#workload-assumptions)\n        - [Scheduling metric](#scheduling-metric)\n        - [First In, First Out (FIFO)](#first-in-first-out-fifo)\n        - [Shortest Job First (SJF)](#shortest-job-first-sjf)\n        - [Shortest Time-toCompletion First (STCF)](#shortest-time-tocompletion-first-stcf)\n        - [A New Metric: Response Time](#a-new-metric-response-time)\n        - [Round Robin (RR)](#round-robin-rr)\n        - [Incorporating I/O](#incorporating-io)\n        - [The Multi-Level Feedback Queue](#the-multi-level-feedback-queue)\n            - [How to Change Priority](#how-to-change-priority)\n            - [The Priority Boost](#the-priority-boost)\n            - [Better Accounting](#better-accounting)\n            - [Tuning MLFQ And Other Issues](#tuning-mlfq-and-other-issues)\n    - [The Abstraction: Address Spaces](#the-abstraction-address-spaces)\n        - [The Address Space](#the-address-space)\n        - [Goals](#goals)\n    - [Interlude: Memory API](#interlude-memory-api)\n    - [Mechanism: Address Translation](#mechanism-address-translation)\n        - [Dynamic (Hardware-based) Relocation](#dynamic-hardware-based-relocation)\n    - [Segmentation](#segmentation)\n        - [Support for Sharing](#support-for-sharing)\n        - [OS Support](#os-support)\n\n<!-- markdown-toc end -->\n\n\n# Virtualization\n\n## The Abstraction: The Process ##\n\nThe abstraction provided by the OS of a running program is something we call a **process**.\n\nWhat consititutes a process:\n\n1. The memory that the process can address (called its **address space**)\n2. Registers\n3. I/O information\n\nProcess API:\n\n- **Create**\n- **Destroy**\n- **Wait**\n- **Miscellaneous Control**\n- **Status**\n  - Running\n  - Ready\n  - Blocked\n\nProcess creation:\n\n1. Loading the code and static data into memory\n2. initializing a stack\n3. Doing other work as related to I/O setup\n\nData structures for process:\n\n```c\n// the registers xv6 will save and restore\n// to stop and subsequently restart a process\nstruct context {\n  int eip;\n  int esp;\n  int ebx;\n  int ecx;\n  int edx;\n  int esi;\n  int edi;\n  int ebp;\n};\n// the different states a process can be in\nenum proc_state { UNUSED, EMBRYO, SLEEPING,\n                  RUNNABLE, RUNNING, ZOMBIE };\n// the information xv6 tracks about each process\n// including its register context and state\nstruct proc {\n  char *mem; // Start of process memory\n  uint sz; // Size of process memory\n  char *kstack; // Bottom of kernel stack\n                // for this process\n  enum proc_state state; // Process state\n  int pid; // Process ID\n  struct proc *parent; // Parent process\n  void *chan; // If non-zero, sleeping on chan\n  int killed; // If non-zero, have been killed\n  struct file *ofile[NOFILE]; // Open files\n  struct inode *cwd; // Current directory\n  struct context context; // Switch here to run process\n  struct trapframe *tf; // Trap frame for the\n                        // current interrupt\n};\n```\n\nProcess API:\n\n- `fork`\n- `wait`\n- `exec`\n\nProblem of direct execution protocol (without limits) \n\n- How can the OS make sure the program doesn't do anything that we don't want it to do, while still running it efficiently\n- How does the operating system stop it from running and switch to another process, thus implementing the **time sharing** we require to virtualize the CPU\n\nLimited Direct Execution protocol\n\n1. At boot time, the kernel initializes the trap table, and the CPU remenbers its location for subsequent use. -> restricted operations\n2. When running a process, the kernel sets up a few things before using a return-from-trap instruction to start the execution of the process; this switches the CPU to user mode and begins running the process. -> switching between processes\n\n## CPU Virtualization (Scheduling Policies) ##\n\n### Workload Assumptions ###\n\nWorkload: the processes running in the system.\n\n### Scheduling metric\n\nTurnaround time: \n\n$$T\\_{turnaround} = T\\_{completion} - T\\_{arrival}$$\n\n### First In, First Out (FIFO)\n\nThere is a problem named convoy effect, where a number of relatively-short potential consumers of a resource get queued behind a heavyweight resource consumer.\n\n### Shortest Job First (SJF) ###\n\nProblem: height weight resource consumer may arrive first.\n\n### Shortest Time-toCompletion First (STCF) ###\n If we knew job lengths, and that jobs only used the CPU, and our only metric was turnaround time, STCF would be a great policy.\n\n### A New Metric: Response Time\n\nResponse time is defined as the time from when the job arrives in a system to the first time it is scheduled: \n\n$$T\\_{response} = T\\_{firsturn} - T\\_{arrival}$$\n\nSTCF is quite bad for response time and interactivity.\n\n### Round Robin (RR)\n\nInstead of running jobs to completion, RR runs a job for a **time slice** and then switches to the next job in the run queue.\n\nRR may exact a noticeable performance cost.\n\nTrade-off: if you are willing to be unfair, you can run shorter jobs to completion, but at the cost of response time; if you instrad value fairness, response time is lowered, but ay the cost of turnaround time.\n\n### Incorporating I/O\n\nBy treating each CPU burst as a job, the scheduler makes sure processes that are \"interactive\" get run frequently. While those interactive jobs are performing I/O, pther CPUintensive jobs run, thus better utilizing the processor.\n\n### The Multi-Level Feedback Queue ###\n\nThe two-fold fundamental problem MLFQ tries to address is two-fold:\n\n1. It would like to optimize *turnaround time*.\n2. MLFQ would like to make a system feel responsive to interactive users and thus minimize *response time*.\n\nStructure of MLFQ: a number of distinct **queues**, each assigned a different **priority level**.\n\nThe basic rules for MLFQ:\n\n- **Rule 1:** If priority(A) > Priority(B), A runs (B doesn't).\n- **Rule 2:** If priority(A) = Priority(B), A & B run in RR.\n\n#### How to Change Priority ####\n\n- **Rule 3:** When a job enters the system, it is placed at the highest priority.\n- **Rule 4a:** If a job uses up an entire time slice while running, its priority is *reduced* (i.e., it moves down one queue).\n- **Rule 4b:** If a job gives up the CPU before the time slice is up, it stays at the same priority level.\n\nProblems With Out Current MLFQ:\n\n1. There is the problem of **starvation**.\n2. A smart user could rewrite their program to **game the scheduler**.\n3. A program may *change its behavior* over time\n\n#### The Priority Boost ####\n\n- **Rule 5:** After some time period *S*, move all the jobs in the system to the top queue.\n\nThe addition of the time period *S* leads to the obvious question: what should *S* be set to?\n\n*S* is a **voo-doo constants**, because they seemed to require some form of black magic to set them correctly.\n\n#### Better Accounting ####\n\nRewrite Rules 4a and 4b to the following single rule to prevent gaming of our scheduler.\n\n- **Rule 4:** Once a job uses up its time allotment at a given level (regardless of how many times it has given up the CPU), its priority is reduced (i.e., it moves down one queue).\n\n#### Tuning MLFQ And Other Issues ####\n\n\n- How big should the time slice be per queue?\n  - Varying time-slice length across different queues.\n  - The high-priority queues are usually given short time slice.\n  - The low-priority queues, in contrast, contain long-running jobs that are CPU-bound hence longer time slices works well.\n- How many queues should there be?\n- How often should priority be boosted in order to avoid starvation and account for changes in behavior?\n\nMany schedulers have a few other features:\n\n- Some schedulers reserve the highest priority levels for operating system work.\n- Some systems also allow some user **advice** to help set priorities.\n\n## The Abstraction: Address Spaces ##\n\nIn order to implement **time sharing** **efficiently** we leave processes in memory to while switching between them. In particular, allowing multiple programs to reside concurrently in memory makes **protection** an important issue.\n\n### The Address Space ###\n\n**Address space** is the running program's view of memory in the sytem.\n\nThe address space of a process contains all of the memory state of the running program:\n\n- Code of the program\n- Stack\n- Heap\n- Etc.\n\nVirtualizing memory: the running program thinks it is loaded into memory at a particular address and has a potentially very large address space.\n\n### Goals ###\n\nTo make sure the OS virtualize memory, we need some goals to guide us:\n\n1. **Transparency:** the OS should implement virtual memory in a way that is invisible to the running program.\n2. **Efficiency**\n3. **Protection:** The OS should make sure to protect processes from one another as well as the OS itself from processes (isolation).\n\n## Interlude: Memory API ##\n\nType of memory:\n\n1. Stack\n2. Heap\n\nAPI:\n\n- `malloc()` \n- `free()`\n\n## Mechanism: Address Translation ##\n\nStrategy in virtualizing memory:\n\n1. Efficiency\n2. Control\n3. Virtualization\n\nAssumptions:\n\n1. Usre's address space must be placed *contiguously* in physical memory\n2. The size of address space is *less than the size of physical memory*\n3. Each address space is eactly the *same size*\n\n### Dynamic (Hardware-based) Relocation ###\n\nTwo hardware registers within each CPU:\n\n1. **Base register**\n2. **Bounds** (sometimes called a limit register)\n  - Bounds register is there to help with protection\n\nIn this setup:\n\n- Programs are written and compiled as if it is loaded at address zero\n- When a program starts running, the OS decides where in physical memory it should be loaded and sets the base register to that value\n\n$$physical\\ address = virtual\\ address + base$$\n\nProblems need to be solved:\n\n1. The OS must take action when a process is created, finding space for its address space in memory.\n2. The OS must do some work when a process is terminated.\n3. The OS must also perform a few additional steps when a context switch occurs.\n4. The OS must provide **exception handlers**.\n\nThe disadvantages of dynamic relocation: when the process stack and heap are not too big, all of the space between the stack and heap is simply wasted (**internal fragmentation**).\n\n## Segmentation ##\n\nA segment is a contiguous portion of the address space of a particular length.\n\nThree logically-different segments:\n\n1. Code\n2. Stack\n3. Heap\n\nOS places each one of those segments in different parts of physical memory to avoid filling physical memory with unused virtual address space.\n\nThus each process needs three base and bounds register pairs.\n\nWhich segment are we referring to?\n\n- Explicit approach: use the top few bits of the virtual address to record the segment type.\n- Implicit approach: the hardware determines the segment by noticing how the address was formed.\n\nPay attention to the stack, which *grows backwards*.\n\n### Support for Sharing ###\n\nTo support sharing, we need a little extra support from the hardware, in the form of **protection bits**.\n\n- Ready\n- Write\n- Execute\n\n### OS Support ###\n\nThere are some new OS issues to support segmentation:\n\n1. What should the OS do on a context switch?\n  - The segment registers must be saved and restored.\n2. How to manage free space in physical memory?\n  - The general problem that arises is that physical memory quickly becomes full of little holes of free space.\n    1. One solution would be to **compact** physical memory by rearranging the existing segments.\n    2. A simpler approach is to use a free-list management algorithm that tries to keep large extents of memory available for allocation. (There are literally hundreds of approaches that people have taken)\n\n## Free-Space Management ##\n\nTo track the size of allocated regions, most allocators store a little bit of extra information in a **header** block which is kept in memory.\n\n```c\ntypedef struct __header_t {\n  int size;\n  int magic;\n} header_t;\n```\n\nIn the structure, the magic number provide additional integrity checking, and other information.\n\nWhen the user calls `free(ptr)`, the library then uses simple pointer arithmetic to figure out where the header begins:\n\n```c\nvoid free(void *ptr) {\n  header_t *hptr = (void *) ptr - sizeof(header_t);\n  // ...\n}\n```\n\n### Basic Strategy ###\n\n- Best fit\n  - Best fit tries to reduce wasted space.\n  - A heavy performance penalty to search for the correct free block.\n- Worst fit\n  - Worst fit tries to leave big chunks free instead of lots of small chunks that can arise from a best-fit approach.\n  - The same performance problem as best fit.\n- First fit\n  - First fit has the advantage of speed.\n  - Sometimes pollutes the beginning of the free list with small objects.\n- Next fit\n\n### Other Approaches ###\n\n- Segregated lists\n- Buddy Allocation\n\n## Pagine: Introduction ##\n\n- Page: fixed-sized units.\n- Page frames: an array of fixed-sized slots.\n\nAdvantages:\n\n1. Flexibility\n2. Simplicity\n\nPage table: a per-process data structure to store address translations.\n\n## Beyond Physical Memory: Mechanisms ##\n\nHow can the OS make use of a larger, slower devices to tranparently provide the illusion of a large virtual address?\n\n### Swap Space ###\n\nSwap space: reserve some space on the disk fgor moving pages back and forth.\n\n- Present bit\n- Page fault\n\nWhy hardware doesn't handle page faults\n\n1. Page faults to disk is so slow that the extra overheads of running software are minimal\n2. To be able to handle a page fault, the hardware would have to understand swap space, how to issue I/Os to the disk, and a lot of other details which it currently doesn't know much about.\n\n## Beyond Physical Memory: Policies ##\n\nHow can the OS decide which page to evict from memory?\n\n### Chache Management ###\n\n- Cache misses/cache hits\n- Average memory access time\n\n$$AMAt = (P_{Hit} \\times T_M) + (P_{Miss} \\times T_D)$$\n\nWhere $T_M$ represents the cost of accessing memory, $T_D$ the cost of accessing disk, $P_{Hit}$ the probability of finding the data in the cache, and P_{Miss} the probability of not finding the data in the cache.\n\n","source":"notes/ostep/index.md","raw":"---\ntitle: \"Operating Systems: Three Easy Pieces\"\ndate: 2016-11-03 14:35:13\nmathjax: true\n---\n\n<!-- markdown-toc start - Don't edit this section. Run M-x markdown-toc-generate-toc again -->\n**Table of Contents**\n\n- [Virtualization](#virtualization)\n    - [The Abstraction: The Process](#the-abstraction-the-process)\n    - [CPU Virtualization (Scheduling Policies)](#cpu-virtualization-scheduling-policies)\n        - [Workload Assumptions](#workload-assumptions)\n        - [Scheduling metric](#scheduling-metric)\n        - [First In, First Out (FIFO)](#first-in-first-out-fifo)\n        - [Shortest Job First (SJF)](#shortest-job-first-sjf)\n        - [Shortest Time-toCompletion First (STCF)](#shortest-time-tocompletion-first-stcf)\n        - [A New Metric: Response Time](#a-new-metric-response-time)\n        - [Round Robin (RR)](#round-robin-rr)\n        - [Incorporating I/O](#incorporating-io)\n        - [The Multi-Level Feedback Queue](#the-multi-level-feedback-queue)\n            - [How to Change Priority](#how-to-change-priority)\n            - [The Priority Boost](#the-priority-boost)\n            - [Better Accounting](#better-accounting)\n            - [Tuning MLFQ And Other Issues](#tuning-mlfq-and-other-issues)\n    - [The Abstraction: Address Spaces](#the-abstraction-address-spaces)\n        - [The Address Space](#the-address-space)\n        - [Goals](#goals)\n    - [Interlude: Memory API](#interlude-memory-api)\n    - [Mechanism: Address Translation](#mechanism-address-translation)\n        - [Dynamic (Hardware-based) Relocation](#dynamic-hardware-based-relocation)\n    - [Segmentation](#segmentation)\n        - [Support for Sharing](#support-for-sharing)\n        - [OS Support](#os-support)\n\n<!-- markdown-toc end -->\n\n\n# Virtualization\n\n## The Abstraction: The Process ##\n\nThe abstraction provided by the OS of a running program is something we call a **process**.\n\nWhat consititutes a process:\n\n1. The memory that the process can address (called its **address space**)\n2. Registers\n3. I/O information\n\nProcess API:\n\n- **Create**\n- **Destroy**\n- **Wait**\n- **Miscellaneous Control**\n- **Status**\n  - Running\n  - Ready\n  - Blocked\n\nProcess creation:\n\n1. Loading the code and static data into memory\n2. initializing a stack\n3. Doing other work as related to I/O setup\n\nData structures for process:\n\n```c\n// the registers xv6 will save and restore\n// to stop and subsequently restart a process\nstruct context {\n  int eip;\n  int esp;\n  int ebx;\n  int ecx;\n  int edx;\n  int esi;\n  int edi;\n  int ebp;\n};\n// the different states a process can be in\nenum proc_state { UNUSED, EMBRYO, SLEEPING,\n                  RUNNABLE, RUNNING, ZOMBIE };\n// the information xv6 tracks about each process\n// including its register context and state\nstruct proc {\n  char *mem; // Start of process memory\n  uint sz; // Size of process memory\n  char *kstack; // Bottom of kernel stack\n                // for this process\n  enum proc_state state; // Process state\n  int pid; // Process ID\n  struct proc *parent; // Parent process\n  void *chan; // If non-zero, sleeping on chan\n  int killed; // If non-zero, have been killed\n  struct file *ofile[NOFILE]; // Open files\n  struct inode *cwd; // Current directory\n  struct context context; // Switch here to run process\n  struct trapframe *tf; // Trap frame for the\n                        // current interrupt\n};\n```\n\nProcess API:\n\n- `fork`\n- `wait`\n- `exec`\n\nProblem of direct execution protocol (without limits) \n\n- How can the OS make sure the program doesn't do anything that we don't want it to do, while still running it efficiently\n- How does the operating system stop it from running and switch to another process, thus implementing the **time sharing** we require to virtualize the CPU\n\nLimited Direct Execution protocol\n\n1. At boot time, the kernel initializes the trap table, and the CPU remenbers its location for subsequent use. -> restricted operations\n2. When running a process, the kernel sets up a few things before using a return-from-trap instruction to start the execution of the process; this switches the CPU to user mode and begins running the process. -> switching between processes\n\n## CPU Virtualization (Scheduling Policies) ##\n\n### Workload Assumptions ###\n\nWorkload: the processes running in the system.\n\n### Scheduling metric\n\nTurnaround time: \n\n$$T\\_{turnaround} = T\\_{completion} - T\\_{arrival}$$\n\n### First In, First Out (FIFO)\n\nThere is a problem named convoy effect, where a number of relatively-short potential consumers of a resource get queued behind a heavyweight resource consumer.\n\n### Shortest Job First (SJF) ###\n\nProblem: height weight resource consumer may arrive first.\n\n### Shortest Time-toCompletion First (STCF) ###\n If we knew job lengths, and that jobs only used the CPU, and our only metric was turnaround time, STCF would be a great policy.\n\n### A New Metric: Response Time\n\nResponse time is defined as the time from when the job arrives in a system to the first time it is scheduled: \n\n$$T\\_{response} = T\\_{firsturn} - T\\_{arrival}$$\n\nSTCF is quite bad for response time and interactivity.\n\n### Round Robin (RR)\n\nInstead of running jobs to completion, RR runs a job for a **time slice** and then switches to the next job in the run queue.\n\nRR may exact a noticeable performance cost.\n\nTrade-off: if you are willing to be unfair, you can run shorter jobs to completion, but at the cost of response time; if you instrad value fairness, response time is lowered, but ay the cost of turnaround time.\n\n### Incorporating I/O\n\nBy treating each CPU burst as a job, the scheduler makes sure processes that are \"interactive\" get run frequently. While those interactive jobs are performing I/O, pther CPUintensive jobs run, thus better utilizing the processor.\n\n### The Multi-Level Feedback Queue ###\n\nThe two-fold fundamental problem MLFQ tries to address is two-fold:\n\n1. It would like to optimize *turnaround time*.\n2. MLFQ would like to make a system feel responsive to interactive users and thus minimize *response time*.\n\nStructure of MLFQ: a number of distinct **queues**, each assigned a different **priority level**.\n\nThe basic rules for MLFQ:\n\n- **Rule 1:** If priority(A) > Priority(B), A runs (B doesn't).\n- **Rule 2:** If priority(A) = Priority(B), A & B run in RR.\n\n#### How to Change Priority ####\n\n- **Rule 3:** When a job enters the system, it is placed at the highest priority.\n- **Rule 4a:** If a job uses up an entire time slice while running, its priority is *reduced* (i.e., it moves down one queue).\n- **Rule 4b:** If a job gives up the CPU before the time slice is up, it stays at the same priority level.\n\nProblems With Out Current MLFQ:\n\n1. There is the problem of **starvation**.\n2. A smart user could rewrite their program to **game the scheduler**.\n3. A program may *change its behavior* over time\n\n#### The Priority Boost ####\n\n- **Rule 5:** After some time period *S*, move all the jobs in the system to the top queue.\n\nThe addition of the time period *S* leads to the obvious question: what should *S* be set to?\n\n*S* is a **voo-doo constants**, because they seemed to require some form of black magic to set them correctly.\n\n#### Better Accounting ####\n\nRewrite Rules 4a and 4b to the following single rule to prevent gaming of our scheduler.\n\n- **Rule 4:** Once a job uses up its time allotment at a given level (regardless of how many times it has given up the CPU), its priority is reduced (i.e., it moves down one queue).\n\n#### Tuning MLFQ And Other Issues ####\n\n\n- How big should the time slice be per queue?\n  - Varying time-slice length across different queues.\n  - The high-priority queues are usually given short time slice.\n  - The low-priority queues, in contrast, contain long-running jobs that are CPU-bound hence longer time slices works well.\n- How many queues should there be?\n- How often should priority be boosted in order to avoid starvation and account for changes in behavior?\n\nMany schedulers have a few other features:\n\n- Some schedulers reserve the highest priority levels for operating system work.\n- Some systems also allow some user **advice** to help set priorities.\n\n## The Abstraction: Address Spaces ##\n\nIn order to implement **time sharing** **efficiently** we leave processes in memory to while switching between them. In particular, allowing multiple programs to reside concurrently in memory makes **protection** an important issue.\n\n### The Address Space ###\n\n**Address space** is the running program's view of memory in the sytem.\n\nThe address space of a process contains all of the memory state of the running program:\n\n- Code of the program\n- Stack\n- Heap\n- Etc.\n\nVirtualizing memory: the running program thinks it is loaded into memory at a particular address and has a potentially very large address space.\n\n### Goals ###\n\nTo make sure the OS virtualize memory, we need some goals to guide us:\n\n1. **Transparency:** the OS should implement virtual memory in a way that is invisible to the running program.\n2. **Efficiency**\n3. **Protection:** The OS should make sure to protect processes from one another as well as the OS itself from processes (isolation).\n\n## Interlude: Memory API ##\n\nType of memory:\n\n1. Stack\n2. Heap\n\nAPI:\n\n- `malloc()` \n- `free()`\n\n## Mechanism: Address Translation ##\n\nStrategy in virtualizing memory:\n\n1. Efficiency\n2. Control\n3. Virtualization\n\nAssumptions:\n\n1. Usre's address space must be placed *contiguously* in physical memory\n2. The size of address space is *less than the size of physical memory*\n3. Each address space is eactly the *same size*\n\n### Dynamic (Hardware-based) Relocation ###\n\nTwo hardware registers within each CPU:\n\n1. **Base register**\n2. **Bounds** (sometimes called a limit register)\n  - Bounds register is there to help with protection\n\nIn this setup:\n\n- Programs are written and compiled as if it is loaded at address zero\n- When a program starts running, the OS decides where in physical memory it should be loaded and sets the base register to that value\n\n$$physical\\ address = virtual\\ address + base$$\n\nProblems need to be solved:\n\n1. The OS must take action when a process is created, finding space for its address space in memory.\n2. The OS must do some work when a process is terminated.\n3. The OS must also perform a few additional steps when a context switch occurs.\n4. The OS must provide **exception handlers**.\n\nThe disadvantages of dynamic relocation: when the process stack and heap are not too big, all of the space between the stack and heap is simply wasted (**internal fragmentation**).\n\n## Segmentation ##\n\nA segment is a contiguous portion of the address space of a particular length.\n\nThree logically-different segments:\n\n1. Code\n2. Stack\n3. Heap\n\nOS places each one of those segments in different parts of physical memory to avoid filling physical memory with unused virtual address space.\n\nThus each process needs three base and bounds register pairs.\n\nWhich segment are we referring to?\n\n- Explicit approach: use the top few bits of the virtual address to record the segment type.\n- Implicit approach: the hardware determines the segment by noticing how the address was formed.\n\nPay attention to the stack, which *grows backwards*.\n\n### Support for Sharing ###\n\nTo support sharing, we need a little extra support from the hardware, in the form of **protection bits**.\n\n- Ready\n- Write\n- Execute\n\n### OS Support ###\n\nThere are some new OS issues to support segmentation:\n\n1. What should the OS do on a context switch?\n  - The segment registers must be saved and restored.\n2. How to manage free space in physical memory?\n  - The general problem that arises is that physical memory quickly becomes full of little holes of free space.\n    1. One solution would be to **compact** physical memory by rearranging the existing segments.\n    2. A simpler approach is to use a free-list management algorithm that tries to keep large extents of memory available for allocation. (There are literally hundreds of approaches that people have taken)\n\n## Free-Space Management ##\n\nTo track the size of allocated regions, most allocators store a little bit of extra information in a **header** block which is kept in memory.\n\n```c\ntypedef struct __header_t {\n  int size;\n  int magic;\n} header_t;\n```\n\nIn the structure, the magic number provide additional integrity checking, and other information.\n\nWhen the user calls `free(ptr)`, the library then uses simple pointer arithmetic to figure out where the header begins:\n\n```c\nvoid free(void *ptr) {\n  header_t *hptr = (void *) ptr - sizeof(header_t);\n  // ...\n}\n```\n\n### Basic Strategy ###\n\n- Best fit\n  - Best fit tries to reduce wasted space.\n  - A heavy performance penalty to search for the correct free block.\n- Worst fit\n  - Worst fit tries to leave big chunks free instead of lots of small chunks that can arise from a best-fit approach.\n  - The same performance problem as best fit.\n- First fit\n  - First fit has the advantage of speed.\n  - Sometimes pollutes the beginning of the free list with small objects.\n- Next fit\n\n### Other Approaches ###\n\n- Segregated lists\n- Buddy Allocation\n\n## Pagine: Introduction ##\n\n- Page: fixed-sized units.\n- Page frames: an array of fixed-sized slots.\n\nAdvantages:\n\n1. Flexibility\n2. Simplicity\n\nPage table: a per-process data structure to store address translations.\n\n## Beyond Physical Memory: Mechanisms ##\n\nHow can the OS make use of a larger, slower devices to tranparently provide the illusion of a large virtual address?\n\n### Swap Space ###\n\nSwap space: reserve some space on the disk fgor moving pages back and forth.\n\n- Present bit\n- Page fault\n\nWhy hardware doesn't handle page faults\n\n1. Page faults to disk is so slow that the extra overheads of running software are minimal\n2. To be able to handle a page fault, the hardware would have to understand swap space, how to issue I/Os to the disk, and a lot of other details which it currently doesn't know much about.\n\n## Beyond Physical Memory: Policies ##\n\nHow can the OS decide which page to evict from memory?\n\n### Chache Management ###\n\n- Cache misses/cache hits\n- Average memory access time\n\n$$AMAt = (P_{Hit} \\times T_M) + (P_{Miss} \\times T_D)$$\n\nWhere $T_M$ represents the cost of accessing memory, $T_D$ the cost of accessing disk, $P_{Hit}$ the probability of finding the data in the cache, and P_{Miss} the probability of not finding the data in the cache.\n\n","updated":"2017-08-07T16:03:06.852Z","path":"notes/ostep/index.html","comments":1,"layout":"page","_id":"cj62dj3o9000720tpdqdew8x5","content":"<!-- markdown-toc start - Don't edit this section. Run M-x markdown-toc-generate-toc again -->\n<p><strong>Table of Contents</strong></p>\n<ul>\n<li><a href=\"#virtualization\">Virtualization</a><ul>\n<li><a href=\"#the-abstraction-the-process\">The Abstraction: The Process</a></li>\n<li><a href=\"#cpu-virtualization-scheduling-policies\">CPU Virtualization (Scheduling Policies)</a><ul>\n<li><a href=\"#workload-assumptions\">Workload Assumptions</a></li>\n<li><a href=\"#scheduling-metric\">Scheduling metric</a></li>\n<li><a href=\"#first-in-first-out-fifo\">First In, First Out (FIFO)</a></li>\n<li><a href=\"#shortest-job-first-sjf\">Shortest Job First (SJF)</a></li>\n<li><a href=\"#shortest-time-tocompletion-first-stcf\">Shortest Time-toCompletion First (STCF)</a></li>\n<li><a href=\"#a-new-metric-response-time\">A New Metric: Response Time</a></li>\n<li><a href=\"#round-robin-rr\">Round Robin (RR)</a></li>\n<li><a href=\"#incorporating-io\">Incorporating I/O</a></li>\n<li><a href=\"#the-multi-level-feedback-queue\">The Multi-Level Feedback Queue</a><ul>\n<li><a href=\"#how-to-change-priority\">How to Change Priority</a></li>\n<li><a href=\"#the-priority-boost\">The Priority Boost</a></li>\n<li><a href=\"#better-accounting\">Better Accounting</a></li>\n<li><a href=\"#tuning-mlfq-and-other-issues\">Tuning MLFQ And Other Issues</a></li>\n</ul>\n</li>\n</ul>\n</li>\n<li><a href=\"#the-abstraction-address-spaces\">The Abstraction: Address Spaces</a><ul>\n<li><a href=\"#the-address-space\">The Address Space</a></li>\n<li><a href=\"#goals\">Goals</a></li>\n</ul>\n</li>\n<li><a href=\"#interlude-memory-api\">Interlude: Memory API</a></li>\n<li><a href=\"#mechanism-address-translation\">Mechanism: Address Translation</a><ul>\n<li><a href=\"#dynamic-hardware-based-relocation\">Dynamic (Hardware-based) Relocation</a></li>\n</ul>\n</li>\n<li><a href=\"#segmentation\">Segmentation</a><ul>\n<li><a href=\"#support-for-sharing\">Support for Sharing</a></li>\n<li><a href=\"#os-support\">OS Support</a></li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>\n<!-- markdown-toc end -->\n<h1 id=\"Virtualization\"><a href=\"#Virtualization\" class=\"headerlink\" title=\"Virtualization\"></a>Virtualization</h1><h2 id=\"The-Abstraction-The-Process\"><a href=\"#The-Abstraction-The-Process\" class=\"headerlink\" title=\"The Abstraction: The Process\"></a>The Abstraction: The Process</h2><p>The abstraction provided by the OS of a running program is something we call a <strong>process</strong>.</p>\n<p>What consititutes a process:</p>\n<ol>\n<li>The memory that the process can address (called its <strong>address space</strong>)</li>\n<li>Registers</li>\n<li>I/O information</li>\n</ol>\n<p>Process API:</p>\n<ul>\n<li><strong>Create</strong></li>\n<li><strong>Destroy</strong></li>\n<li><strong>Wait</strong></li>\n<li><strong>Miscellaneous Control</strong></li>\n<li><strong>Status</strong><ul>\n<li>Running</li>\n<li>Ready</li>\n<li>Blocked</li>\n</ul>\n</li>\n</ul>\n<p>Process creation:</p>\n<ol>\n<li>Loading the code and static data into memory</li>\n<li>initializing a stack</li>\n<li>Doing other work as related to I/O setup</li>\n</ol>\n<p>Data structures for process:</p>\n<figure class=\"highlight c\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div><div class=\"line\">24</div><div class=\"line\">25</div><div class=\"line\">26</div><div class=\"line\">27</div><div class=\"line\">28</div><div class=\"line\">29</div><div class=\"line\">30</div><div class=\"line\">31</div><div class=\"line\">32</div><div class=\"line\">33</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"comment\">// the registers xv6 will save and restore</span></div><div class=\"line\"><span class=\"comment\">// to stop and subsequently restart a process</span></div><div class=\"line\"><span class=\"class\"><span class=\"keyword\">struct</span> <span class=\"title\">context</span> &#123;</span></div><div class=\"line\">  <span class=\"keyword\">int</span> eip;</div><div class=\"line\">  <span class=\"keyword\">int</span> esp;</div><div class=\"line\">  <span class=\"keyword\">int</span> ebx;</div><div class=\"line\">  <span class=\"keyword\">int</span> ecx;</div><div class=\"line\">  <span class=\"keyword\">int</span> edx;</div><div class=\"line\">  <span class=\"keyword\">int</span> esi;</div><div class=\"line\">  <span class=\"keyword\">int</span> edi;</div><div class=\"line\">  <span class=\"keyword\">int</span> ebp;</div><div class=\"line\">&#125;;</div><div class=\"line\"><span class=\"comment\">// the different states a process can be in</span></div><div class=\"line\"><span class=\"keyword\">enum</span> proc_state &#123; UNUSED, EMBRYO, SLEEPING,</div><div class=\"line\">                  RUNNABLE, RUNNING, ZOMBIE &#125;;</div><div class=\"line\"><span class=\"comment\">// the information xv6 tracks about each process</span></div><div class=\"line\"><span class=\"comment\">// including its register context and state</span></div><div class=\"line\"><span class=\"class\"><span class=\"keyword\">struct</span> <span class=\"title\">proc</span> &#123;</span></div><div class=\"line\">  <span class=\"keyword\">char</span> *mem; <span class=\"comment\">// Start of process memory</span></div><div class=\"line\">  uint sz; <span class=\"comment\">// Size of process memory</span></div><div class=\"line\">  <span class=\"keyword\">char</span> *kstack; <span class=\"comment\">// Bottom of kernel stack</span></div><div class=\"line\">                <span class=\"comment\">// for this process</span></div><div class=\"line\">  <span class=\"keyword\">enum</span> proc_state state; <span class=\"comment\">// Process state</span></div><div class=\"line\">  <span class=\"keyword\">int</span> pid; <span class=\"comment\">// Process ID</span></div><div class=\"line\">  <span class=\"class\"><span class=\"keyword\">struct</span> <span class=\"title\">proc</span> *<span class=\"title\">parent</span>;</span> <span class=\"comment\">// Parent process</span></div><div class=\"line\">  <span class=\"keyword\">void</span> *chan; <span class=\"comment\">// If non-zero, sleeping on chan</span></div><div class=\"line\">  <span class=\"keyword\">int</span> killed; <span class=\"comment\">// If non-zero, have been killed</span></div><div class=\"line\">  <span class=\"class\"><span class=\"keyword\">struct</span> <span class=\"title\">file</span> *<span class=\"title\">ofile</span>[<span class=\"title\">NOFILE</span>];</span> <span class=\"comment\">// Open files</span></div><div class=\"line\">  <span class=\"class\"><span class=\"keyword\">struct</span> <span class=\"title\">inode</span> *<span class=\"title\">cwd</span>;</span> <span class=\"comment\">// Current directory</span></div><div class=\"line\">  <span class=\"class\"><span class=\"keyword\">struct</span> <span class=\"title\">context</span> <span class=\"title\">context</span>;</span> <span class=\"comment\">// Switch here to run process</span></div><div class=\"line\">  <span class=\"class\"><span class=\"keyword\">struct</span> <span class=\"title\">trapframe</span> *<span class=\"title\">tf</span>;</span> <span class=\"comment\">// Trap frame for the</span></div><div class=\"line\">                        <span class=\"comment\">// current interrupt</span></div><div class=\"line\">&#125;;</div></pre></td></tr></table></figure>\n<p>Process API:</p>\n<ul>\n<li><code>fork</code></li>\n<li><code>wait</code></li>\n<li><code>exec</code></li>\n</ul>\n<p>Problem of direct execution protocol (without limits) </p>\n<ul>\n<li>How can the OS make sure the program doesn’t do anything that we don’t want it to do, while still running it efficiently</li>\n<li>How does the operating system stop it from running and switch to another process, thus implementing the <strong>time sharing</strong> we require to virtualize the CPU</li>\n</ul>\n<p>Limited Direct Execution protocol</p>\n<ol>\n<li>At boot time, the kernel initializes the trap table, and the CPU remenbers its location for subsequent use. -&gt; restricted operations</li>\n<li>When running a process, the kernel sets up a few things before using a return-from-trap instruction to start the execution of the process; this switches the CPU to user mode and begins running the process. -&gt; switching between processes</li>\n</ol>\n<h2 id=\"CPU-Virtualization-Scheduling-Policies\"><a href=\"#CPU-Virtualization-Scheduling-Policies\" class=\"headerlink\" title=\"CPU Virtualization (Scheduling Policies)\"></a>CPU Virtualization (Scheduling Policies)</h2><h3 id=\"Workload-Assumptions\"><a href=\"#Workload-Assumptions\" class=\"headerlink\" title=\"Workload Assumptions\"></a>Workload Assumptions</h3><p>Workload: the processes running in the system.</p>\n<h3 id=\"Scheduling-metric\"><a href=\"#Scheduling-metric\" class=\"headerlink\" title=\"Scheduling metric\"></a>Scheduling metric</h3><p>Turnaround time: </p>\n<p>$$T_{turnaround} = T_{completion} - T_{arrival}$$</p>\n<h3 id=\"First-In-First-Out-FIFO\"><a href=\"#First-In-First-Out-FIFO\" class=\"headerlink\" title=\"First In, First Out (FIFO)\"></a>First In, First Out (FIFO)</h3><p>There is a problem named convoy effect, where a number of relatively-short potential consumers of a resource get queued behind a heavyweight resource consumer.</p>\n<h3 id=\"Shortest-Job-First-SJF\"><a href=\"#Shortest-Job-First-SJF\" class=\"headerlink\" title=\"Shortest Job First (SJF)\"></a>Shortest Job First (SJF)</h3><p>Problem: height weight resource consumer may arrive first.</p>\n<h3 id=\"Shortest-Time-toCompletion-First-STCF\"><a href=\"#Shortest-Time-toCompletion-First-STCF\" class=\"headerlink\" title=\"Shortest Time-toCompletion First (STCF)\"></a>Shortest Time-toCompletion First (STCF)</h3><p> If we knew job lengths, and that jobs only used the CPU, and our only metric was turnaround time, STCF would be a great policy.</p>\n<h3 id=\"A-New-Metric-Response-Time\"><a href=\"#A-New-Metric-Response-Time\" class=\"headerlink\" title=\"A New Metric: Response Time\"></a>A New Metric: Response Time</h3><p>Response time is defined as the time from when the job arrives in a system to the first time it is scheduled: </p>\n<p>$$T_{response} = T_{firsturn} - T_{arrival}$$</p>\n<p>STCF is quite bad for response time and interactivity.</p>\n<h3 id=\"Round-Robin-RR\"><a href=\"#Round-Robin-RR\" class=\"headerlink\" title=\"Round Robin (RR)\"></a>Round Robin (RR)</h3><p>Instead of running jobs to completion, RR runs a job for a <strong>time slice</strong> and then switches to the next job in the run queue.</p>\n<p>RR may exact a noticeable performance cost.</p>\n<p>Trade-off: if you are willing to be unfair, you can run shorter jobs to completion, but at the cost of response time; if you instrad value fairness, response time is lowered, but ay the cost of turnaround time.</p>\n<h3 id=\"Incorporating-I-O\"><a href=\"#Incorporating-I-O\" class=\"headerlink\" title=\"Incorporating I/O\"></a>Incorporating I/O</h3><p>By treating each CPU burst as a job, the scheduler makes sure processes that are “interactive” get run frequently. While those interactive jobs are performing I/O, pther CPUintensive jobs run, thus better utilizing the processor.</p>\n<h3 id=\"The-Multi-Level-Feedback-Queue\"><a href=\"#The-Multi-Level-Feedback-Queue\" class=\"headerlink\" title=\"The Multi-Level Feedback Queue\"></a>The Multi-Level Feedback Queue</h3><p>The two-fold fundamental problem MLFQ tries to address is two-fold:</p>\n<ol>\n<li>It would like to optimize <em>turnaround time</em>.</li>\n<li>MLFQ would like to make a system feel responsive to interactive users and thus minimize <em>response time</em>.</li>\n</ol>\n<p>Structure of MLFQ: a number of distinct <strong>queues</strong>, each assigned a different <strong>priority level</strong>.</p>\n<p>The basic rules for MLFQ:</p>\n<ul>\n<li><strong>Rule 1:</strong> If priority(A) &gt; Priority(B), A runs (B doesn’t).</li>\n<li><strong>Rule 2:</strong> If priority(A) = Priority(B), A &amp; B run in RR.</li>\n</ul>\n<h4 id=\"How-to-Change-Priority\"><a href=\"#How-to-Change-Priority\" class=\"headerlink\" title=\"How to Change Priority\"></a>How to Change Priority</h4><ul>\n<li><strong>Rule 3:</strong> When a job enters the system, it is placed at the highest priority.</li>\n<li><strong>Rule 4a:</strong> If a job uses up an entire time slice while running, its priority is <em>reduced</em> (i.e., it moves down one queue).</li>\n<li><strong>Rule 4b:</strong> If a job gives up the CPU before the time slice is up, it stays at the same priority level.</li>\n</ul>\n<p>Problems With Out Current MLFQ:</p>\n<ol>\n<li>There is the problem of <strong>starvation</strong>.</li>\n<li>A smart user could rewrite their program to <strong>game the scheduler</strong>.</li>\n<li>A program may <em>change its behavior</em> over time</li>\n</ol>\n<h4 id=\"The-Priority-Boost\"><a href=\"#The-Priority-Boost\" class=\"headerlink\" title=\"The Priority Boost\"></a>The Priority Boost</h4><ul>\n<li><strong>Rule 5:</strong> After some time period <em>S</em>, move all the jobs in the system to the top queue.</li>\n</ul>\n<p>The addition of the time period <em>S</em> leads to the obvious question: what should <em>S</em> be set to?</p>\n<p><em>S</em> is a <strong>voo-doo constants</strong>, because they seemed to require some form of black magic to set them correctly.</p>\n<h4 id=\"Better-Accounting\"><a href=\"#Better-Accounting\" class=\"headerlink\" title=\"Better Accounting\"></a>Better Accounting</h4><p>Rewrite Rules 4a and 4b to the following single rule to prevent gaming of our scheduler.</p>\n<ul>\n<li><strong>Rule 4:</strong> Once a job uses up its time allotment at a given level (regardless of how many times it has given up the CPU), its priority is reduced (i.e., it moves down one queue).</li>\n</ul>\n<h4 id=\"Tuning-MLFQ-And-Other-Issues\"><a href=\"#Tuning-MLFQ-And-Other-Issues\" class=\"headerlink\" title=\"Tuning MLFQ And Other Issues\"></a>Tuning MLFQ And Other Issues</h4><ul>\n<li>How big should the time slice be per queue?<ul>\n<li>Varying time-slice length across different queues.</li>\n<li>The high-priority queues are usually given short time slice.</li>\n<li>The low-priority queues, in contrast, contain long-running jobs that are CPU-bound hence longer time slices works well.</li>\n</ul>\n</li>\n<li>How many queues should there be?</li>\n<li>How often should priority be boosted in order to avoid starvation and account for changes in behavior?</li>\n</ul>\n<p>Many schedulers have a few other features:</p>\n<ul>\n<li>Some schedulers reserve the highest priority levels for operating system work.</li>\n<li>Some systems also allow some user <strong>advice</strong> to help set priorities.</li>\n</ul>\n<h2 id=\"The-Abstraction-Address-Spaces\"><a href=\"#The-Abstraction-Address-Spaces\" class=\"headerlink\" title=\"The Abstraction: Address Spaces\"></a>The Abstraction: Address Spaces</h2><p>In order to implement <strong>time sharing</strong> <strong>efficiently</strong> we leave processes in memory to while switching between them. In particular, allowing multiple programs to reside concurrently in memory makes <strong>protection</strong> an important issue.</p>\n<h3 id=\"The-Address-Space\"><a href=\"#The-Address-Space\" class=\"headerlink\" title=\"The Address Space\"></a>The Address Space</h3><p><strong>Address space</strong> is the running program’s view of memory in the sytem.</p>\n<p>The address space of a process contains all of the memory state of the running program:</p>\n<ul>\n<li>Code of the program</li>\n<li>Stack</li>\n<li>Heap</li>\n<li>Etc.</li>\n</ul>\n<p>Virtualizing memory: the running program thinks it is loaded into memory at a particular address and has a potentially very large address space.</p>\n<h3 id=\"Goals\"><a href=\"#Goals\" class=\"headerlink\" title=\"Goals\"></a>Goals</h3><p>To make sure the OS virtualize memory, we need some goals to guide us:</p>\n<ol>\n<li><strong>Transparency:</strong> the OS should implement virtual memory in a way that is invisible to the running program.</li>\n<li><strong>Efficiency</strong></li>\n<li><strong>Protection:</strong> The OS should make sure to protect processes from one another as well as the OS itself from processes (isolation).</li>\n</ol>\n<h2 id=\"Interlude-Memory-API\"><a href=\"#Interlude-Memory-API\" class=\"headerlink\" title=\"Interlude: Memory API\"></a>Interlude: Memory API</h2><p>Type of memory:</p>\n<ol>\n<li>Stack</li>\n<li>Heap</li>\n</ol>\n<p>API:</p>\n<ul>\n<li><code>malloc()</code> </li>\n<li><code>free()</code></li>\n</ul>\n<h2 id=\"Mechanism-Address-Translation\"><a href=\"#Mechanism-Address-Translation\" class=\"headerlink\" title=\"Mechanism: Address Translation\"></a>Mechanism: Address Translation</h2><p>Strategy in virtualizing memory:</p>\n<ol>\n<li>Efficiency</li>\n<li>Control</li>\n<li>Virtualization</li>\n</ol>\n<p>Assumptions:</p>\n<ol>\n<li>Usre’s address space must be placed <em>contiguously</em> in physical memory</li>\n<li>The size of address space is <em>less than the size of physical memory</em></li>\n<li>Each address space is eactly the <em>same size</em></li>\n</ol>\n<h3 id=\"Dynamic-Hardware-based-Relocation\"><a href=\"#Dynamic-Hardware-based-Relocation\" class=\"headerlink\" title=\"Dynamic (Hardware-based) Relocation\"></a>Dynamic (Hardware-based) Relocation</h3><p>Two hardware registers within each CPU:</p>\n<ol>\n<li><strong>Base register</strong></li>\n<li><strong>Bounds</strong> (sometimes called a limit register)<ul>\n<li>Bounds register is there to help with protection</li>\n</ul>\n</li>\n</ol>\n<p>In this setup:</p>\n<ul>\n<li>Programs are written and compiled as if it is loaded at address zero</li>\n<li>When a program starts running, the OS decides where in physical memory it should be loaded and sets the base register to that value</li>\n</ul>\n<p>$$physical\\ address = virtual\\ address + base$$</p>\n<p>Problems need to be solved:</p>\n<ol>\n<li>The OS must take action when a process is created, finding space for its address space in memory.</li>\n<li>The OS must do some work when a process is terminated.</li>\n<li>The OS must also perform a few additional steps when a context switch occurs.</li>\n<li>The OS must provide <strong>exception handlers</strong>.</li>\n</ol>\n<p>The disadvantages of dynamic relocation: when the process stack and heap are not too big, all of the space between the stack and heap is simply wasted (<strong>internal fragmentation</strong>).</p>\n<h2 id=\"Segmentation\"><a href=\"#Segmentation\" class=\"headerlink\" title=\"Segmentation\"></a>Segmentation</h2><p>A segment is a contiguous portion of the address space of a particular length.</p>\n<p>Three logically-different segments:</p>\n<ol>\n<li>Code</li>\n<li>Stack</li>\n<li>Heap</li>\n</ol>\n<p>OS places each one of those segments in different parts of physical memory to avoid filling physical memory with unused virtual address space.</p>\n<p>Thus each process needs three base and bounds register pairs.</p>\n<p>Which segment are we referring to?</p>\n<ul>\n<li>Explicit approach: use the top few bits of the virtual address to record the segment type.</li>\n<li>Implicit approach: the hardware determines the segment by noticing how the address was formed.</li>\n</ul>\n<p>Pay attention to the stack, which <em>grows backwards</em>.</p>\n<h3 id=\"Support-for-Sharing\"><a href=\"#Support-for-Sharing\" class=\"headerlink\" title=\"Support for Sharing\"></a>Support for Sharing</h3><p>To support sharing, we need a little extra support from the hardware, in the form of <strong>protection bits</strong>.</p>\n<ul>\n<li>Ready</li>\n<li>Write</li>\n<li>Execute</li>\n</ul>\n<h3 id=\"OS-Support\"><a href=\"#OS-Support\" class=\"headerlink\" title=\"OS Support\"></a>OS Support</h3><p>There are some new OS issues to support segmentation:</p>\n<ol>\n<li>What should the OS do on a context switch?<ul>\n<li>The segment registers must be saved and restored.</li>\n</ul>\n</li>\n<li>How to manage free space in physical memory?<ul>\n<li>The general problem that arises is that physical memory quickly becomes full of little holes of free space.<ol>\n<li>One solution would be to <strong>compact</strong> physical memory by rearranging the existing segments.</li>\n<li>A simpler approach is to use a free-list management algorithm that tries to keep large extents of memory available for allocation. (There are literally hundreds of approaches that people have taken)</li>\n</ol>\n</li>\n</ul>\n</li>\n</ol>\n<h2 id=\"Free-Space-Management\"><a href=\"#Free-Space-Management\" class=\"headerlink\" title=\"Free-Space Management\"></a>Free-Space Management</h2><p>To track the size of allocated regions, most allocators store a little bit of extra information in a <strong>header</strong> block which is kept in memory.</p>\n<figure class=\"highlight c\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"keyword\">typedef</span> <span class=\"class\"><span class=\"keyword\">struct</span> __<span class=\"title\">header_t</span> &#123;</span></div><div class=\"line\">  <span class=\"keyword\">int</span> size;</div><div class=\"line\">  <span class=\"keyword\">int</span> magic;</div><div class=\"line\">&#125; <span class=\"keyword\">header_t</span>;</div></pre></td></tr></table></figure>\n<p>In the structure, the magic number provide additional integrity checking, and other information.</p>\n<p>When the user calls <code>free(ptr)</code>, the library then uses simple pointer arithmetic to figure out where the header begins:</p>\n<figure class=\"highlight c\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">free</span><span class=\"params\">(<span class=\"keyword\">void</span> *ptr)</span> </span>&#123;</div><div class=\"line\">  <span class=\"keyword\">header_t</span> *hptr = (<span class=\"keyword\">void</span> *) ptr - <span class=\"keyword\">sizeof</span>(<span class=\"keyword\">header_t</span>);</div><div class=\"line\">  <span class=\"comment\">// ...</span></div><div class=\"line\">&#125;</div></pre></td></tr></table></figure>\n<h3 id=\"Basic-Strategy\"><a href=\"#Basic-Strategy\" class=\"headerlink\" title=\"Basic Strategy\"></a>Basic Strategy</h3><ul>\n<li>Best fit<ul>\n<li>Best fit tries to reduce wasted space.</li>\n<li>A heavy performance penalty to search for the correct free block.</li>\n</ul>\n</li>\n<li>Worst fit<ul>\n<li>Worst fit tries to leave big chunks free instead of lots of small chunks that can arise from a best-fit approach.</li>\n<li>The same performance problem as best fit.</li>\n</ul>\n</li>\n<li>First fit<ul>\n<li>First fit has the advantage of speed.</li>\n<li>Sometimes pollutes the beginning of the free list with small objects.</li>\n</ul>\n</li>\n<li>Next fit</li>\n</ul>\n<h3 id=\"Other-Approaches\"><a href=\"#Other-Approaches\" class=\"headerlink\" title=\"Other Approaches\"></a>Other Approaches</h3><ul>\n<li>Segregated lists</li>\n<li>Buddy Allocation</li>\n</ul>\n<h2 id=\"Pagine-Introduction\"><a href=\"#Pagine-Introduction\" class=\"headerlink\" title=\"Pagine: Introduction\"></a>Pagine: Introduction</h2><ul>\n<li>Page: fixed-sized units.</li>\n<li>Page frames: an array of fixed-sized slots.</li>\n</ul>\n<p>Advantages:</p>\n<ol>\n<li>Flexibility</li>\n<li>Simplicity</li>\n</ol>\n<p>Page table: a per-process data structure to store address translations.</p>\n<h2 id=\"Beyond-Physical-Memory-Mechanisms\"><a href=\"#Beyond-Physical-Memory-Mechanisms\" class=\"headerlink\" title=\"Beyond Physical Memory: Mechanisms\"></a>Beyond Physical Memory: Mechanisms</h2><p>How can the OS make use of a larger, slower devices to tranparently provide the illusion of a large virtual address?</p>\n<h3 id=\"Swap-Space\"><a href=\"#Swap-Space\" class=\"headerlink\" title=\"Swap Space\"></a>Swap Space</h3><p>Swap space: reserve some space on the disk fgor moving pages back and forth.</p>\n<ul>\n<li>Present bit</li>\n<li>Page fault</li>\n</ul>\n<p>Why hardware doesn’t handle page faults</p>\n<ol>\n<li>Page faults to disk is so slow that the extra overheads of running software are minimal</li>\n<li>To be able to handle a page fault, the hardware would have to understand swap space, how to issue I/Os to the disk, and a lot of other details which it currently doesn’t know much about.</li>\n</ol>\n<h2 id=\"Beyond-Physical-Memory-Policies\"><a href=\"#Beyond-Physical-Memory-Policies\" class=\"headerlink\" title=\"Beyond Physical Memory: Policies\"></a>Beyond Physical Memory: Policies</h2><p>How can the OS decide which page to evict from memory?</p>\n<h3 id=\"Chache-Management\"><a href=\"#Chache-Management\" class=\"headerlink\" title=\"Chache Management\"></a>Chache Management</h3><ul>\n<li>Cache misses/cache hits</li>\n<li>Average memory access time</li>\n</ul>\n<p>$$AMAt = (P_{Hit} \\times T<em>M) + (P</em>{Miss} \\times T_D)$$</p>\n<p>Where $T_M$ represents the cost of accessing memory, $T<em>D$ the cost of accessing disk, $P</em>{Hit}$ the probability of finding the data in the cache, and P_{Miss} the probability of not finding the data in the cache.</p>\n","excerpt":"","more":"<!-- markdown-toc start - Don't edit this section. Run M-x markdown-toc-generate-toc again -->\n<p><strong>Table of Contents</strong></p>\n<ul>\n<li><a href=\"#virtualization\">Virtualization</a><ul>\n<li><a href=\"#the-abstraction-the-process\">The Abstraction: The Process</a></li>\n<li><a href=\"#cpu-virtualization-scheduling-policies\">CPU Virtualization (Scheduling Policies)</a><ul>\n<li><a href=\"#workload-assumptions\">Workload Assumptions</a></li>\n<li><a href=\"#scheduling-metric\">Scheduling metric</a></li>\n<li><a href=\"#first-in-first-out-fifo\">First In, First Out (FIFO)</a></li>\n<li><a href=\"#shortest-job-first-sjf\">Shortest Job First (SJF)</a></li>\n<li><a href=\"#shortest-time-tocompletion-first-stcf\">Shortest Time-toCompletion First (STCF)</a></li>\n<li><a href=\"#a-new-metric-response-time\">A New Metric: Response Time</a></li>\n<li><a href=\"#round-robin-rr\">Round Robin (RR)</a></li>\n<li><a href=\"#incorporating-io\">Incorporating I/O</a></li>\n<li><a href=\"#the-multi-level-feedback-queue\">The Multi-Level Feedback Queue</a><ul>\n<li><a href=\"#how-to-change-priority\">How to Change Priority</a></li>\n<li><a href=\"#the-priority-boost\">The Priority Boost</a></li>\n<li><a href=\"#better-accounting\">Better Accounting</a></li>\n<li><a href=\"#tuning-mlfq-and-other-issues\">Tuning MLFQ And Other Issues</a></li>\n</ul>\n</li>\n</ul>\n</li>\n<li><a href=\"#the-abstraction-address-spaces\">The Abstraction: Address Spaces</a><ul>\n<li><a href=\"#the-address-space\">The Address Space</a></li>\n<li><a href=\"#goals\">Goals</a></li>\n</ul>\n</li>\n<li><a href=\"#interlude-memory-api\">Interlude: Memory API</a></li>\n<li><a href=\"#mechanism-address-translation\">Mechanism: Address Translation</a><ul>\n<li><a href=\"#dynamic-hardware-based-relocation\">Dynamic (Hardware-based) Relocation</a></li>\n</ul>\n</li>\n<li><a href=\"#segmentation\">Segmentation</a><ul>\n<li><a href=\"#support-for-sharing\">Support for Sharing</a></li>\n<li><a href=\"#os-support\">OS Support</a></li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>\n<!-- markdown-toc end -->\n<h1 id=\"Virtualization\"><a href=\"#Virtualization\" class=\"headerlink\" title=\"Virtualization\"></a>Virtualization</h1><h2 id=\"The-Abstraction-The-Process\"><a href=\"#The-Abstraction-The-Process\" class=\"headerlink\" title=\"The Abstraction: The Process\"></a>The Abstraction: The Process</h2><p>The abstraction provided by the OS of a running program is something we call a <strong>process</strong>.</p>\n<p>What consititutes a process:</p>\n<ol>\n<li>The memory that the process can address (called its <strong>address space</strong>)</li>\n<li>Registers</li>\n<li>I/O information</li>\n</ol>\n<p>Process API:</p>\n<ul>\n<li><strong>Create</strong></li>\n<li><strong>Destroy</strong></li>\n<li><strong>Wait</strong></li>\n<li><strong>Miscellaneous Control</strong></li>\n<li><strong>Status</strong><ul>\n<li>Running</li>\n<li>Ready</li>\n<li>Blocked</li>\n</ul>\n</li>\n</ul>\n<p>Process creation:</p>\n<ol>\n<li>Loading the code and static data into memory</li>\n<li>initializing a stack</li>\n<li>Doing other work as related to I/O setup</li>\n</ol>\n<p>Data structures for process:</p>\n<figure class=\"highlight c\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div><div class=\"line\">24</div><div class=\"line\">25</div><div class=\"line\">26</div><div class=\"line\">27</div><div class=\"line\">28</div><div class=\"line\">29</div><div class=\"line\">30</div><div class=\"line\">31</div><div class=\"line\">32</div><div class=\"line\">33</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"comment\">// the registers xv6 will save and restore</span></div><div class=\"line\"><span class=\"comment\">// to stop and subsequently restart a process</span></div><div class=\"line\"><span class=\"class\"><span class=\"keyword\">struct</span> <span class=\"title\">context</span> &#123;</span></div><div class=\"line\">  <span class=\"keyword\">int</span> eip;</div><div class=\"line\">  <span class=\"keyword\">int</span> esp;</div><div class=\"line\">  <span class=\"keyword\">int</span> ebx;</div><div class=\"line\">  <span class=\"keyword\">int</span> ecx;</div><div class=\"line\">  <span class=\"keyword\">int</span> edx;</div><div class=\"line\">  <span class=\"keyword\">int</span> esi;</div><div class=\"line\">  <span class=\"keyword\">int</span> edi;</div><div class=\"line\">  <span class=\"keyword\">int</span> ebp;</div><div class=\"line\">&#125;;</div><div class=\"line\"><span class=\"comment\">// the different states a process can be in</span></div><div class=\"line\"><span class=\"keyword\">enum</span> proc_state &#123; UNUSED, EMBRYO, SLEEPING,</div><div class=\"line\">                  RUNNABLE, RUNNING, ZOMBIE &#125;;</div><div class=\"line\"><span class=\"comment\">// the information xv6 tracks about each process</span></div><div class=\"line\"><span class=\"comment\">// including its register context and state</span></div><div class=\"line\"><span class=\"class\"><span class=\"keyword\">struct</span> <span class=\"title\">proc</span> &#123;</span></div><div class=\"line\">  <span class=\"keyword\">char</span> *mem; <span class=\"comment\">// Start of process memory</span></div><div class=\"line\">  uint sz; <span class=\"comment\">// Size of process memory</span></div><div class=\"line\">  <span class=\"keyword\">char</span> *kstack; <span class=\"comment\">// Bottom of kernel stack</span></div><div class=\"line\">                <span class=\"comment\">// for this process</span></div><div class=\"line\">  <span class=\"keyword\">enum</span> proc_state state; <span class=\"comment\">// Process state</span></div><div class=\"line\">  <span class=\"keyword\">int</span> pid; <span class=\"comment\">// Process ID</span></div><div class=\"line\">  <span class=\"class\"><span class=\"keyword\">struct</span> <span class=\"title\">proc</span> *<span class=\"title\">parent</span>;</span> <span class=\"comment\">// Parent process</span></div><div class=\"line\">  <span class=\"keyword\">void</span> *chan; <span class=\"comment\">// If non-zero, sleeping on chan</span></div><div class=\"line\">  <span class=\"keyword\">int</span> killed; <span class=\"comment\">// If non-zero, have been killed</span></div><div class=\"line\">  <span class=\"class\"><span class=\"keyword\">struct</span> <span class=\"title\">file</span> *<span class=\"title\">ofile</span>[<span class=\"title\">NOFILE</span>];</span> <span class=\"comment\">// Open files</span></div><div class=\"line\">  <span class=\"class\"><span class=\"keyword\">struct</span> <span class=\"title\">inode</span> *<span class=\"title\">cwd</span>;</span> <span class=\"comment\">// Current directory</span></div><div class=\"line\">  <span class=\"class\"><span class=\"keyword\">struct</span> <span class=\"title\">context</span> <span class=\"title\">context</span>;</span> <span class=\"comment\">// Switch here to run process</span></div><div class=\"line\">  <span class=\"class\"><span class=\"keyword\">struct</span> <span class=\"title\">trapframe</span> *<span class=\"title\">tf</span>;</span> <span class=\"comment\">// Trap frame for the</span></div><div class=\"line\">                        <span class=\"comment\">// current interrupt</span></div><div class=\"line\">&#125;;</div></pre></td></tr></table></figure>\n<p>Process API:</p>\n<ul>\n<li><code>fork</code></li>\n<li><code>wait</code></li>\n<li><code>exec</code></li>\n</ul>\n<p>Problem of direct execution protocol (without limits) </p>\n<ul>\n<li>How can the OS make sure the program doesn’t do anything that we don’t want it to do, while still running it efficiently</li>\n<li>How does the operating system stop it from running and switch to another process, thus implementing the <strong>time sharing</strong> we require to virtualize the CPU</li>\n</ul>\n<p>Limited Direct Execution protocol</p>\n<ol>\n<li>At boot time, the kernel initializes the trap table, and the CPU remenbers its location for subsequent use. -&gt; restricted operations</li>\n<li>When running a process, the kernel sets up a few things before using a return-from-trap instruction to start the execution of the process; this switches the CPU to user mode and begins running the process. -&gt; switching between processes</li>\n</ol>\n<h2 id=\"CPU-Virtualization-Scheduling-Policies\"><a href=\"#CPU-Virtualization-Scheduling-Policies\" class=\"headerlink\" title=\"CPU Virtualization (Scheduling Policies)\"></a>CPU Virtualization (Scheduling Policies)</h2><h3 id=\"Workload-Assumptions\"><a href=\"#Workload-Assumptions\" class=\"headerlink\" title=\"Workload Assumptions\"></a>Workload Assumptions</h3><p>Workload: the processes running in the system.</p>\n<h3 id=\"Scheduling-metric\"><a href=\"#Scheduling-metric\" class=\"headerlink\" title=\"Scheduling metric\"></a>Scheduling metric</h3><p>Turnaround time: </p>\n<p>$$T_{turnaround} = T_{completion} - T_{arrival}$$</p>\n<h3 id=\"First-In-First-Out-FIFO\"><a href=\"#First-In-First-Out-FIFO\" class=\"headerlink\" title=\"First In, First Out (FIFO)\"></a>First In, First Out (FIFO)</h3><p>There is a problem named convoy effect, where a number of relatively-short potential consumers of a resource get queued behind a heavyweight resource consumer.</p>\n<h3 id=\"Shortest-Job-First-SJF\"><a href=\"#Shortest-Job-First-SJF\" class=\"headerlink\" title=\"Shortest Job First (SJF)\"></a>Shortest Job First (SJF)</h3><p>Problem: height weight resource consumer may arrive first.</p>\n<h3 id=\"Shortest-Time-toCompletion-First-STCF\"><a href=\"#Shortest-Time-toCompletion-First-STCF\" class=\"headerlink\" title=\"Shortest Time-toCompletion First (STCF)\"></a>Shortest Time-toCompletion First (STCF)</h3><p> If we knew job lengths, and that jobs only used the CPU, and our only metric was turnaround time, STCF would be a great policy.</p>\n<h3 id=\"A-New-Metric-Response-Time\"><a href=\"#A-New-Metric-Response-Time\" class=\"headerlink\" title=\"A New Metric: Response Time\"></a>A New Metric: Response Time</h3><p>Response time is defined as the time from when the job arrives in a system to the first time it is scheduled: </p>\n<p>$$T_{response} = T_{firsturn} - T_{arrival}$$</p>\n<p>STCF is quite bad for response time and interactivity.</p>\n<h3 id=\"Round-Robin-RR\"><a href=\"#Round-Robin-RR\" class=\"headerlink\" title=\"Round Robin (RR)\"></a>Round Robin (RR)</h3><p>Instead of running jobs to completion, RR runs a job for a <strong>time slice</strong> and then switches to the next job in the run queue.</p>\n<p>RR may exact a noticeable performance cost.</p>\n<p>Trade-off: if you are willing to be unfair, you can run shorter jobs to completion, but at the cost of response time; if you instrad value fairness, response time is lowered, but ay the cost of turnaround time.</p>\n<h3 id=\"Incorporating-I-O\"><a href=\"#Incorporating-I-O\" class=\"headerlink\" title=\"Incorporating I/O\"></a>Incorporating I/O</h3><p>By treating each CPU burst as a job, the scheduler makes sure processes that are “interactive” get run frequently. While those interactive jobs are performing I/O, pther CPUintensive jobs run, thus better utilizing the processor.</p>\n<h3 id=\"The-Multi-Level-Feedback-Queue\"><a href=\"#The-Multi-Level-Feedback-Queue\" class=\"headerlink\" title=\"The Multi-Level Feedback Queue\"></a>The Multi-Level Feedback Queue</h3><p>The two-fold fundamental problem MLFQ tries to address is two-fold:</p>\n<ol>\n<li>It would like to optimize <em>turnaround time</em>.</li>\n<li>MLFQ would like to make a system feel responsive to interactive users and thus minimize <em>response time</em>.</li>\n</ol>\n<p>Structure of MLFQ: a number of distinct <strong>queues</strong>, each assigned a different <strong>priority level</strong>.</p>\n<p>The basic rules for MLFQ:</p>\n<ul>\n<li><strong>Rule 1:</strong> If priority(A) &gt; Priority(B), A runs (B doesn’t).</li>\n<li><strong>Rule 2:</strong> If priority(A) = Priority(B), A &amp; B run in RR.</li>\n</ul>\n<h4 id=\"How-to-Change-Priority\"><a href=\"#How-to-Change-Priority\" class=\"headerlink\" title=\"How to Change Priority\"></a>How to Change Priority</h4><ul>\n<li><strong>Rule 3:</strong> When a job enters the system, it is placed at the highest priority.</li>\n<li><strong>Rule 4a:</strong> If a job uses up an entire time slice while running, its priority is <em>reduced</em> (i.e., it moves down one queue).</li>\n<li><strong>Rule 4b:</strong> If a job gives up the CPU before the time slice is up, it stays at the same priority level.</li>\n</ul>\n<p>Problems With Out Current MLFQ:</p>\n<ol>\n<li>There is the problem of <strong>starvation</strong>.</li>\n<li>A smart user could rewrite their program to <strong>game the scheduler</strong>.</li>\n<li>A program may <em>change its behavior</em> over time</li>\n</ol>\n<h4 id=\"The-Priority-Boost\"><a href=\"#The-Priority-Boost\" class=\"headerlink\" title=\"The Priority Boost\"></a>The Priority Boost</h4><ul>\n<li><strong>Rule 5:</strong> After some time period <em>S</em>, move all the jobs in the system to the top queue.</li>\n</ul>\n<p>The addition of the time period <em>S</em> leads to the obvious question: what should <em>S</em> be set to?</p>\n<p><em>S</em> is a <strong>voo-doo constants</strong>, because they seemed to require some form of black magic to set them correctly.</p>\n<h4 id=\"Better-Accounting\"><a href=\"#Better-Accounting\" class=\"headerlink\" title=\"Better Accounting\"></a>Better Accounting</h4><p>Rewrite Rules 4a and 4b to the following single rule to prevent gaming of our scheduler.</p>\n<ul>\n<li><strong>Rule 4:</strong> Once a job uses up its time allotment at a given level (regardless of how many times it has given up the CPU), its priority is reduced (i.e., it moves down one queue).</li>\n</ul>\n<h4 id=\"Tuning-MLFQ-And-Other-Issues\"><a href=\"#Tuning-MLFQ-And-Other-Issues\" class=\"headerlink\" title=\"Tuning MLFQ And Other Issues\"></a>Tuning MLFQ And Other Issues</h4><ul>\n<li>How big should the time slice be per queue?<ul>\n<li>Varying time-slice length across different queues.</li>\n<li>The high-priority queues are usually given short time slice.</li>\n<li>The low-priority queues, in contrast, contain long-running jobs that are CPU-bound hence longer time slices works well.</li>\n</ul>\n</li>\n<li>How many queues should there be?</li>\n<li>How often should priority be boosted in order to avoid starvation and account for changes in behavior?</li>\n</ul>\n<p>Many schedulers have a few other features:</p>\n<ul>\n<li>Some schedulers reserve the highest priority levels for operating system work.</li>\n<li>Some systems also allow some user <strong>advice</strong> to help set priorities.</li>\n</ul>\n<h2 id=\"The-Abstraction-Address-Spaces\"><a href=\"#The-Abstraction-Address-Spaces\" class=\"headerlink\" title=\"The Abstraction: Address Spaces\"></a>The Abstraction: Address Spaces</h2><p>In order to implement <strong>time sharing</strong> <strong>efficiently</strong> we leave processes in memory to while switching between them. In particular, allowing multiple programs to reside concurrently in memory makes <strong>protection</strong> an important issue.</p>\n<h3 id=\"The-Address-Space\"><a href=\"#The-Address-Space\" class=\"headerlink\" title=\"The Address Space\"></a>The Address Space</h3><p><strong>Address space</strong> is the running program’s view of memory in the sytem.</p>\n<p>The address space of a process contains all of the memory state of the running program:</p>\n<ul>\n<li>Code of the program</li>\n<li>Stack</li>\n<li>Heap</li>\n<li>Etc.</li>\n</ul>\n<p>Virtualizing memory: the running program thinks it is loaded into memory at a particular address and has a potentially very large address space.</p>\n<h3 id=\"Goals\"><a href=\"#Goals\" class=\"headerlink\" title=\"Goals\"></a>Goals</h3><p>To make sure the OS virtualize memory, we need some goals to guide us:</p>\n<ol>\n<li><strong>Transparency:</strong> the OS should implement virtual memory in a way that is invisible to the running program.</li>\n<li><strong>Efficiency</strong></li>\n<li><strong>Protection:</strong> The OS should make sure to protect processes from one another as well as the OS itself from processes (isolation).</li>\n</ol>\n<h2 id=\"Interlude-Memory-API\"><a href=\"#Interlude-Memory-API\" class=\"headerlink\" title=\"Interlude: Memory API\"></a>Interlude: Memory API</h2><p>Type of memory:</p>\n<ol>\n<li>Stack</li>\n<li>Heap</li>\n</ol>\n<p>API:</p>\n<ul>\n<li><code>malloc()</code> </li>\n<li><code>free()</code></li>\n</ul>\n<h2 id=\"Mechanism-Address-Translation\"><a href=\"#Mechanism-Address-Translation\" class=\"headerlink\" title=\"Mechanism: Address Translation\"></a>Mechanism: Address Translation</h2><p>Strategy in virtualizing memory:</p>\n<ol>\n<li>Efficiency</li>\n<li>Control</li>\n<li>Virtualization</li>\n</ol>\n<p>Assumptions:</p>\n<ol>\n<li>Usre’s address space must be placed <em>contiguously</em> in physical memory</li>\n<li>The size of address space is <em>less than the size of physical memory</em></li>\n<li>Each address space is eactly the <em>same size</em></li>\n</ol>\n<h3 id=\"Dynamic-Hardware-based-Relocation\"><a href=\"#Dynamic-Hardware-based-Relocation\" class=\"headerlink\" title=\"Dynamic (Hardware-based) Relocation\"></a>Dynamic (Hardware-based) Relocation</h3><p>Two hardware registers within each CPU:</p>\n<ol>\n<li><strong>Base register</strong></li>\n<li><strong>Bounds</strong> (sometimes called a limit register)<ul>\n<li>Bounds register is there to help with protection</li>\n</ul>\n</li>\n</ol>\n<p>In this setup:</p>\n<ul>\n<li>Programs are written and compiled as if it is loaded at address zero</li>\n<li>When a program starts running, the OS decides where in physical memory it should be loaded and sets the base register to that value</li>\n</ul>\n<p>$$physical\\ address = virtual\\ address + base$$</p>\n<p>Problems need to be solved:</p>\n<ol>\n<li>The OS must take action when a process is created, finding space for its address space in memory.</li>\n<li>The OS must do some work when a process is terminated.</li>\n<li>The OS must also perform a few additional steps when a context switch occurs.</li>\n<li>The OS must provide <strong>exception handlers</strong>.</li>\n</ol>\n<p>The disadvantages of dynamic relocation: when the process stack and heap are not too big, all of the space between the stack and heap is simply wasted (<strong>internal fragmentation</strong>).</p>\n<h2 id=\"Segmentation\"><a href=\"#Segmentation\" class=\"headerlink\" title=\"Segmentation\"></a>Segmentation</h2><p>A segment is a contiguous portion of the address space of a particular length.</p>\n<p>Three logically-different segments:</p>\n<ol>\n<li>Code</li>\n<li>Stack</li>\n<li>Heap</li>\n</ol>\n<p>OS places each one of those segments in different parts of physical memory to avoid filling physical memory with unused virtual address space.</p>\n<p>Thus each process needs three base and bounds register pairs.</p>\n<p>Which segment are we referring to?</p>\n<ul>\n<li>Explicit approach: use the top few bits of the virtual address to record the segment type.</li>\n<li>Implicit approach: the hardware determines the segment by noticing how the address was formed.</li>\n</ul>\n<p>Pay attention to the stack, which <em>grows backwards</em>.</p>\n<h3 id=\"Support-for-Sharing\"><a href=\"#Support-for-Sharing\" class=\"headerlink\" title=\"Support for Sharing\"></a>Support for Sharing</h3><p>To support sharing, we need a little extra support from the hardware, in the form of <strong>protection bits</strong>.</p>\n<ul>\n<li>Ready</li>\n<li>Write</li>\n<li>Execute</li>\n</ul>\n<h3 id=\"OS-Support\"><a href=\"#OS-Support\" class=\"headerlink\" title=\"OS Support\"></a>OS Support</h3><p>There are some new OS issues to support segmentation:</p>\n<ol>\n<li>What should the OS do on a context switch?<ul>\n<li>The segment registers must be saved and restored.</li>\n</ul>\n</li>\n<li>How to manage free space in physical memory?<ul>\n<li>The general problem that arises is that physical memory quickly becomes full of little holes of free space.<ol>\n<li>One solution would be to <strong>compact</strong> physical memory by rearranging the existing segments.</li>\n<li>A simpler approach is to use a free-list management algorithm that tries to keep large extents of memory available for allocation. (There are literally hundreds of approaches that people have taken)</li>\n</ol>\n</li>\n</ul>\n</li>\n</ol>\n<h2 id=\"Free-Space-Management\"><a href=\"#Free-Space-Management\" class=\"headerlink\" title=\"Free-Space Management\"></a>Free-Space Management</h2><p>To track the size of allocated regions, most allocators store a little bit of extra information in a <strong>header</strong> block which is kept in memory.</p>\n<figure class=\"highlight c\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"keyword\">typedef</span> <span class=\"class\"><span class=\"keyword\">struct</span> __<span class=\"title\">header_t</span> &#123;</span></div><div class=\"line\">  <span class=\"keyword\">int</span> size;</div><div class=\"line\">  <span class=\"keyword\">int</span> magic;</div><div class=\"line\">&#125; <span class=\"keyword\">header_t</span>;</div></pre></td></tr></table></figure>\n<p>In the structure, the magic number provide additional integrity checking, and other information.</p>\n<p>When the user calls <code>free(ptr)</code>, the library then uses simple pointer arithmetic to figure out where the header begins:</p>\n<figure class=\"highlight c\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">free</span><span class=\"params\">(<span class=\"keyword\">void</span> *ptr)</span> </span>&#123;</div><div class=\"line\">  <span class=\"keyword\">header_t</span> *hptr = (<span class=\"keyword\">void</span> *) ptr - <span class=\"keyword\">sizeof</span>(<span class=\"keyword\">header_t</span>);</div><div class=\"line\">  <span class=\"comment\">// ...</span></div><div class=\"line\">&#125;</div></pre></td></tr></table></figure>\n<h3 id=\"Basic-Strategy\"><a href=\"#Basic-Strategy\" class=\"headerlink\" title=\"Basic Strategy\"></a>Basic Strategy</h3><ul>\n<li>Best fit<ul>\n<li>Best fit tries to reduce wasted space.</li>\n<li>A heavy performance penalty to search for the correct free block.</li>\n</ul>\n</li>\n<li>Worst fit<ul>\n<li>Worst fit tries to leave big chunks free instead of lots of small chunks that can arise from a best-fit approach.</li>\n<li>The same performance problem as best fit.</li>\n</ul>\n</li>\n<li>First fit<ul>\n<li>First fit has the advantage of speed.</li>\n<li>Sometimes pollutes the beginning of the free list with small objects.</li>\n</ul>\n</li>\n<li>Next fit</li>\n</ul>\n<h3 id=\"Other-Approaches\"><a href=\"#Other-Approaches\" class=\"headerlink\" title=\"Other Approaches\"></a>Other Approaches</h3><ul>\n<li>Segregated lists</li>\n<li>Buddy Allocation</li>\n</ul>\n<h2 id=\"Pagine-Introduction\"><a href=\"#Pagine-Introduction\" class=\"headerlink\" title=\"Pagine: Introduction\"></a>Pagine: Introduction</h2><ul>\n<li>Page: fixed-sized units.</li>\n<li>Page frames: an array of fixed-sized slots.</li>\n</ul>\n<p>Advantages:</p>\n<ol>\n<li>Flexibility</li>\n<li>Simplicity</li>\n</ol>\n<p>Page table: a per-process data structure to store address translations.</p>\n<h2 id=\"Beyond-Physical-Memory-Mechanisms\"><a href=\"#Beyond-Physical-Memory-Mechanisms\" class=\"headerlink\" title=\"Beyond Physical Memory: Mechanisms\"></a>Beyond Physical Memory: Mechanisms</h2><p>How can the OS make use of a larger, slower devices to tranparently provide the illusion of a large virtual address?</p>\n<h3 id=\"Swap-Space\"><a href=\"#Swap-Space\" class=\"headerlink\" title=\"Swap Space\"></a>Swap Space</h3><p>Swap space: reserve some space on the disk fgor moving pages back and forth.</p>\n<ul>\n<li>Present bit</li>\n<li>Page fault</li>\n</ul>\n<p>Why hardware doesn’t handle page faults</p>\n<ol>\n<li>Page faults to disk is so slow that the extra overheads of running software are minimal</li>\n<li>To be able to handle a page fault, the hardware would have to understand swap space, how to issue I/Os to the disk, and a lot of other details which it currently doesn’t know much about.</li>\n</ol>\n<h2 id=\"Beyond-Physical-Memory-Policies\"><a href=\"#Beyond-Physical-Memory-Policies\" class=\"headerlink\" title=\"Beyond Physical Memory: Policies\"></a>Beyond Physical Memory: Policies</h2><p>How can the OS decide which page to evict from memory?</p>\n<h3 id=\"Chache-Management\"><a href=\"#Chache-Management\" class=\"headerlink\" title=\"Chache Management\"></a>Chache Management</h3><ul>\n<li>Cache misses/cache hits</li>\n<li>Average memory access time</li>\n</ul>\n<p>$$AMAt = (P_{Hit} \\times T<em>M) + (P</em>{Miss} \\times T_D)$$</p>\n<p>Where $T_M$ represents the cost of accessing memory, $T<em>D$ the cost of accessing disk, $P</em>{Hit}$ the probability of finding the data in the cache, and P_{Miss} the probability of not finding the data in the cache.</p>\n"}],"Post":[{"title":"Haskell踩坑总结","date":"2016-11-27T12:15:47.000Z","_content":"\n这个是我前些年自学Haskell时整理的资料，现在可能有点过时了，不过应该还有些参考价值吧。\n\n## 入门参考\n\n- 参考 http://stackoverflow.com/questions/1012573/getting-started-with-haskell\n  - 先看*LYAH*，看到Functor时可以开始做*haskell 99 problems*。不用全做完，做到差不多有感觉了开始看LYAH的Functor, Applicative和Monad。\n  - 看*RWH*的Monad部分，看得懂就多看几章，看不懂就先放着。\n  - 接着可以刷 https://wiki.haskell.org/Tutorials#Using_monads 这个页面里Monad的一些paper和文章。\n    - *How to build a monadic interpreter in one day*: 挺好的文章，写一个迷你的解释器，可看可不看，建议不看而去看Philip Wadler的两篇Monad的论文。\n    - *Monad Transformers Explained*, *MonadCont under the hood*: 这两篇讲的是MT和CPS，建议弄懂Monad后再挑战这种更蛋疼的概念。\n    - *IO inside*: 是讲IO Monad的，这种Monad比较简单，文章写得很好。\n    - *The Haskell Programmer's Guide to the IO Monad - Don't Panic*: 没看，讲范畴论（category theory）的，不做研究不需要了解，建议等想深入了再学。\n    - *Systematic Design of Monads*: 没看，不过看上去挺有趣的。\n    - *All About Monads*: 可以看一部分，有些内容比较难，那些东西晚点看。\n    - 还有一些文章我也没接触，大家可以挑自己感兴趣的看看。\n  - 和上面可以同时进行的是刷[Philip Wadler](http://homepages.inf.ed.ac.uk/wadler/)关于Monad的论文，推荐*Monads for functional programming*和*The essence of functional programming*。\n  - 感觉对Monad有一些掌握后可以尝试用Haskell写一个Lisp的解释器 https://en.wikibooks.org/wiki/Write_Yourself_a_Scheme_in_48_Hours \n- 接下来可以看看Penn的*CIS194*，这门课每年的在Monad之后讲的内容不一样，包括一些并发、GUI和类型推导理论里的最前沿的内容。可以看看然后做做里面的作业。\n- 接着可以开始做*[NICTA course](https://github.com/NICTA/course)*，非常好的Haskell进阶课程，形式也很有意思。**（强烈推荐这个课程，里面的代码一定要尽量写完，非常有意思）**\n- 这个阶段后看自己的兴趣选择喜欢的东西学学。\n\n## 资料汇总\n\n- https://en.wikibooks.org/wiki/Haskell\n  - 很重要的参考资料，遇到不懂的概念都可以去看看\n- https://www.haskell.org/onlinereport/haskell2010/\n  - 语言标准\n- Hoogle: https://www.haskell.org/hoogle/\n  - 查Package和Package源代码的地方，Haskell的代码写得都非常漂亮，流行Package的作者又全是大神，没事可以多看看他们的代码。\n- Stackage: https://www.stackage.org/\n  - 另一个查Package和源代码的地方，我记得这边有时能查到一些Hoogle查不到的Package。\n- https://wiki.haskell.org/Typeclassopedia\n  - 介绍了各种Type，写得非常好，推荐。\n- http://www.seas.upenn.edu/~cis194/resources.html\n  - 很多有用的资料。\n- http://stackoverflow.com/questions/1012573/getting-started-with-haskell\n  - 不全，但给了些学习的路线图。\n- http://www.zhihu.com/topic/19593103\n  - 知乎的Haskell页面，挺多好的中文资料，但装逼犯（比如轮子）比较多。\n  - http://www.zhihu.com/question/20193745/answer/37300535 推荐这个帖子\n- http://www.scs.stanford.edu/14sp-cs240h/\n  - S大的Haskell课程，偏工程，讲课的两位都是大神，助教也是大神。\n- http://courses.cms.caltech.edu/cs11/material/haskell/\n  - 加州理工的Haskell课程，比较老了，一些资料不错。\n- https://wiki.haskell.org/Learning_Haskell 和 https://wiki.haskell.org/Tutorials\n  - 官方的资料收集页面，很多好东西，可以玩一年。\n- http://research.microsoft.com/en-us/um/people/simonpj/papers/papers.html\n  - SPJ大神的主页，Haskell的创造者之一（Wadler也是），理论和码功都是大神级的。\n- http://dotat.at/tmp/danvy-filinski-mscs92.pdf\n  - 一篇关于CPS的论文，CPS算是一种古老的黑科技，Lisp, Haskell, JS, Scala, C++里面都有，但是个人觉得Lisp和Haskell用得最优雅。\n- *The Little Schemer*\n  - 王垠在印第安纳的老板写的scheme的书，介绍了CPS和Y Combinator，学Haskell可以参考。\n- Idris \n  - http://www.idris-lang.org/\n  - 一个通用的依赖类型的函数式编程语言，可以看做升级版的Haskell。\n- Coq\n  - https://coq.inria.fr/\n  - 一个用来定理证明的依赖类型的函数式编程语言。\n  - *[Software Foundations](https://www.cis.upenn.edu/~bcpierce/sf/current/index.html)*，programming language领域很著名的书，没看过也要知道名字=w=\n  \n## 编辑器\n\n- Emacs: Haskell mode\n- Spacemacs: Haskell Layer （我目前用的，基于Emacs的Haskell mode）\n- Vim: Haskell mode\n- Intellij: Haskell plugin\n\n推荐Emacs，Vim没用过，但Emacs的Haskell mode比Vim的出名很多（带有bias），所以Emacs写Haskell应该更方便。IntelliJ不够智能，快捷键不好用，对cabal和stackage集成效果也不如Emacs。*（前几年的情况，现在不知道了）*\n\n## Haskell安装\n\n- 推荐使用Haskell官网的Haskell Platform。\n\n*注：这个好像过时了，现在比较流行用stackage，毕竟cabal hell太讨厌了。*\n","source":"_posts/Haskell踩坑总结.md","raw":"---\ntitle: Haskell踩坑总结\ndate: 2016-11-27 20:15:47\ntags: Programming\n---\n\n这个是我前些年自学Haskell时整理的资料，现在可能有点过时了，不过应该还有些参考价值吧。\n\n## 入门参考\n\n- 参考 http://stackoverflow.com/questions/1012573/getting-started-with-haskell\n  - 先看*LYAH*，看到Functor时可以开始做*haskell 99 problems*。不用全做完，做到差不多有感觉了开始看LYAH的Functor, Applicative和Monad。\n  - 看*RWH*的Monad部分，看得懂就多看几章，看不懂就先放着。\n  - 接着可以刷 https://wiki.haskell.org/Tutorials#Using_monads 这个页面里Monad的一些paper和文章。\n    - *How to build a monadic interpreter in one day*: 挺好的文章，写一个迷你的解释器，可看可不看，建议不看而去看Philip Wadler的两篇Monad的论文。\n    - *Monad Transformers Explained*, *MonadCont under the hood*: 这两篇讲的是MT和CPS，建议弄懂Monad后再挑战这种更蛋疼的概念。\n    - *IO inside*: 是讲IO Monad的，这种Monad比较简单，文章写得很好。\n    - *The Haskell Programmer's Guide to the IO Monad - Don't Panic*: 没看，讲范畴论（category theory）的，不做研究不需要了解，建议等想深入了再学。\n    - *Systematic Design of Monads*: 没看，不过看上去挺有趣的。\n    - *All About Monads*: 可以看一部分，有些内容比较难，那些东西晚点看。\n    - 还有一些文章我也没接触，大家可以挑自己感兴趣的看看。\n  - 和上面可以同时进行的是刷[Philip Wadler](http://homepages.inf.ed.ac.uk/wadler/)关于Monad的论文，推荐*Monads for functional programming*和*The essence of functional programming*。\n  - 感觉对Monad有一些掌握后可以尝试用Haskell写一个Lisp的解释器 https://en.wikibooks.org/wiki/Write_Yourself_a_Scheme_in_48_Hours \n- 接下来可以看看Penn的*CIS194*，这门课每年的在Monad之后讲的内容不一样，包括一些并发、GUI和类型推导理论里的最前沿的内容。可以看看然后做做里面的作业。\n- 接着可以开始做*[NICTA course](https://github.com/NICTA/course)*，非常好的Haskell进阶课程，形式也很有意思。**（强烈推荐这个课程，里面的代码一定要尽量写完，非常有意思）**\n- 这个阶段后看自己的兴趣选择喜欢的东西学学。\n\n## 资料汇总\n\n- https://en.wikibooks.org/wiki/Haskell\n  - 很重要的参考资料，遇到不懂的概念都可以去看看\n- https://www.haskell.org/onlinereport/haskell2010/\n  - 语言标准\n- Hoogle: https://www.haskell.org/hoogle/\n  - 查Package和Package源代码的地方，Haskell的代码写得都非常漂亮，流行Package的作者又全是大神，没事可以多看看他们的代码。\n- Stackage: https://www.stackage.org/\n  - 另一个查Package和源代码的地方，我记得这边有时能查到一些Hoogle查不到的Package。\n- https://wiki.haskell.org/Typeclassopedia\n  - 介绍了各种Type，写得非常好，推荐。\n- http://www.seas.upenn.edu/~cis194/resources.html\n  - 很多有用的资料。\n- http://stackoverflow.com/questions/1012573/getting-started-with-haskell\n  - 不全，但给了些学习的路线图。\n- http://www.zhihu.com/topic/19593103\n  - 知乎的Haskell页面，挺多好的中文资料，但装逼犯（比如轮子）比较多。\n  - http://www.zhihu.com/question/20193745/answer/37300535 推荐这个帖子\n- http://www.scs.stanford.edu/14sp-cs240h/\n  - S大的Haskell课程，偏工程，讲课的两位都是大神，助教也是大神。\n- http://courses.cms.caltech.edu/cs11/material/haskell/\n  - 加州理工的Haskell课程，比较老了，一些资料不错。\n- https://wiki.haskell.org/Learning_Haskell 和 https://wiki.haskell.org/Tutorials\n  - 官方的资料收集页面，很多好东西，可以玩一年。\n- http://research.microsoft.com/en-us/um/people/simonpj/papers/papers.html\n  - SPJ大神的主页，Haskell的创造者之一（Wadler也是），理论和码功都是大神级的。\n- http://dotat.at/tmp/danvy-filinski-mscs92.pdf\n  - 一篇关于CPS的论文，CPS算是一种古老的黑科技，Lisp, Haskell, JS, Scala, C++里面都有，但是个人觉得Lisp和Haskell用得最优雅。\n- *The Little Schemer*\n  - 王垠在印第安纳的老板写的scheme的书，介绍了CPS和Y Combinator，学Haskell可以参考。\n- Idris \n  - http://www.idris-lang.org/\n  - 一个通用的依赖类型的函数式编程语言，可以看做升级版的Haskell。\n- Coq\n  - https://coq.inria.fr/\n  - 一个用来定理证明的依赖类型的函数式编程语言。\n  - *[Software Foundations](https://www.cis.upenn.edu/~bcpierce/sf/current/index.html)*，programming language领域很著名的书，没看过也要知道名字=w=\n  \n## 编辑器\n\n- Emacs: Haskell mode\n- Spacemacs: Haskell Layer （我目前用的，基于Emacs的Haskell mode）\n- Vim: Haskell mode\n- Intellij: Haskell plugin\n\n推荐Emacs，Vim没用过，但Emacs的Haskell mode比Vim的出名很多（带有bias），所以Emacs写Haskell应该更方便。IntelliJ不够智能，快捷键不好用，对cabal和stackage集成效果也不如Emacs。*（前几年的情况，现在不知道了）*\n\n## Haskell安装\n\n- 推荐使用Haskell官网的Haskell Platform。\n\n*注：这个好像过时了，现在比较流行用stackage，毕竟cabal hell太讨厌了。*\n","slug":"Haskell踩坑总结","published":1,"updated":"2017-08-07T16:03:06.834Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cj62dj3l0000120tp6es2mngm","content":"<p>这个是我前些年自学Haskell时整理的资料，现在可能有点过时了，不过应该还有些参考价值吧。</p>\n<h2 id=\"入门参考\"><a href=\"#入门参考\" class=\"headerlink\" title=\"入门参考\"></a>入门参考</h2><ul>\n<li>参考 <a href=\"http://stackoverflow.com/questions/1012573/getting-started-with-haskell\" target=\"_blank\" rel=\"external\">http://stackoverflow.com/questions/1012573/getting-started-with-haskell</a><ul>\n<li>先看<em>LYAH</em>，看到Functor时可以开始做<em>haskell 99 problems</em>。不用全做完，做到差不多有感觉了开始看LYAH的Functor, Applicative和Monad。</li>\n<li>看<em>RWH</em>的Monad部分，看得懂就多看几章，看不懂就先放着。</li>\n<li>接着可以刷 <a href=\"https://wiki.haskell.org/Tutorials#Using_monads\" target=\"_blank\" rel=\"external\">https://wiki.haskell.org/Tutorials#Using_monads</a> 这个页面里Monad的一些paper和文章。<ul>\n<li><em>How to build a monadic interpreter in one day</em>: 挺好的文章，写一个迷你的解释器，可看可不看，建议不看而去看Philip Wadler的两篇Monad的论文。</li>\n<li><em>Monad Transformers Explained</em>, <em>MonadCont under the hood</em>: 这两篇讲的是MT和CPS，建议弄懂Monad后再挑战这种更蛋疼的概念。</li>\n<li><em>IO inside</em>: 是讲IO Monad的，这种Monad比较简单，文章写得很好。</li>\n<li><em>The Haskell Programmer’s Guide to the IO Monad - Don’t Panic</em>: 没看，讲范畴论（category theory）的，不做研究不需要了解，建议等想深入了再学。</li>\n<li><em>Systematic Design of Monads</em>: 没看，不过看上去挺有趣的。</li>\n<li><em>All About Monads</em>: 可以看一部分，有些内容比较难，那些东西晚点看。</li>\n<li>还有一些文章我也没接触，大家可以挑自己感兴趣的看看。</li>\n</ul>\n</li>\n<li>和上面可以同时进行的是刷<a href=\"http://homepages.inf.ed.ac.uk/wadler/\" target=\"_blank\" rel=\"external\">Philip Wadler</a>关于Monad的论文，推荐<em>Monads for functional programming</em>和<em>The essence of functional programming</em>。</li>\n<li>感觉对Monad有一些掌握后可以尝试用Haskell写一个Lisp的解释器 <a href=\"https://en.wikibooks.org/wiki/Write_Yourself_a_Scheme_in_48_Hours\" target=\"_blank\" rel=\"external\">https://en.wikibooks.org/wiki/Write_Yourself_a_Scheme_in_48_Hours</a> </li>\n</ul>\n</li>\n<li>接下来可以看看Penn的<em>CIS194</em>，这门课每年的在Monad之后讲的内容不一样，包括一些并发、GUI和类型推导理论里的最前沿的内容。可以看看然后做做里面的作业。</li>\n<li>接着可以开始做<em><a href=\"https://github.com/NICTA/course\" target=\"_blank\" rel=\"external\">NICTA course</a></em>，非常好的Haskell进阶课程，形式也很有意思。<strong>（强烈推荐这个课程，里面的代码一定要尽量写完，非常有意思）</strong></li>\n<li>这个阶段后看自己的兴趣选择喜欢的东西学学。</li>\n</ul>\n<h2 id=\"资料汇总\"><a href=\"#资料汇总\" class=\"headerlink\" title=\"资料汇总\"></a>资料汇总</h2><ul>\n<li><a href=\"https://en.wikibooks.org/wiki/Haskell\" target=\"_blank\" rel=\"external\">https://en.wikibooks.org/wiki/Haskell</a><ul>\n<li>很重要的参考资料，遇到不懂的概念都可以去看看</li>\n</ul>\n</li>\n<li><a href=\"https://www.haskell.org/onlinereport/haskell2010/\" target=\"_blank\" rel=\"external\">https://www.haskell.org/onlinereport/haskell2010/</a><ul>\n<li>语言标准</li>\n</ul>\n</li>\n<li>Hoogle: <a href=\"https://www.haskell.org/hoogle/\" target=\"_blank\" rel=\"external\">https://www.haskell.org/hoogle/</a><ul>\n<li>查Package和Package源代码的地方，Haskell的代码写得都非常漂亮，流行Package的作者又全是大神，没事可以多看看他们的代码。</li>\n</ul>\n</li>\n<li>Stackage: <a href=\"https://www.stackage.org/\" target=\"_blank\" rel=\"external\">https://www.stackage.org/</a><ul>\n<li>另一个查Package和源代码的地方，我记得这边有时能查到一些Hoogle查不到的Package。</li>\n</ul>\n</li>\n<li><a href=\"https://wiki.haskell.org/Typeclassopedia\" target=\"_blank\" rel=\"external\">https://wiki.haskell.org/Typeclassopedia</a><ul>\n<li>介绍了各种Type，写得非常好，推荐。</li>\n</ul>\n</li>\n<li><a href=\"http://www.seas.upenn.edu/~cis194/resources.html\" target=\"_blank\" rel=\"external\">http://www.seas.upenn.edu/~cis194/resources.html</a><ul>\n<li>很多有用的资料。</li>\n</ul>\n</li>\n<li><a href=\"http://stackoverflow.com/questions/1012573/getting-started-with-haskell\" target=\"_blank\" rel=\"external\">http://stackoverflow.com/questions/1012573/getting-started-with-haskell</a><ul>\n<li>不全，但给了些学习的路线图。</li>\n</ul>\n</li>\n<li><a href=\"http://www.zhihu.com/topic/19593103\" target=\"_blank\" rel=\"external\">http://www.zhihu.com/topic/19593103</a><ul>\n<li>知乎的Haskell页面，挺多好的中文资料，但装逼犯（比如轮子）比较多。</li>\n<li><a href=\"http://www.zhihu.com/question/20193745/answer/37300535\" target=\"_blank\" rel=\"external\">http://www.zhihu.com/question/20193745/answer/37300535</a> 推荐这个帖子</li>\n</ul>\n</li>\n<li><a href=\"http://www.scs.stanford.edu/14sp-cs240h/\" target=\"_blank\" rel=\"external\">http://www.scs.stanford.edu/14sp-cs240h/</a><ul>\n<li>S大的Haskell课程，偏工程，讲课的两位都是大神，助教也是大神。</li>\n</ul>\n</li>\n<li><a href=\"http://courses.cms.caltech.edu/cs11/material/haskell/\" target=\"_blank\" rel=\"external\">http://courses.cms.caltech.edu/cs11/material/haskell/</a><ul>\n<li>加州理工的Haskell课程，比较老了，一些资料不错。</li>\n</ul>\n</li>\n<li><a href=\"https://wiki.haskell.org/Learning_Haskell\" target=\"_blank\" rel=\"external\">https://wiki.haskell.org/Learning_Haskell</a> 和 <a href=\"https://wiki.haskell.org/Tutorials\" target=\"_blank\" rel=\"external\">https://wiki.haskell.org/Tutorials</a><ul>\n<li>官方的资料收集页面，很多好东西，可以玩一年。</li>\n</ul>\n</li>\n<li><a href=\"http://research.microsoft.com/en-us/um/people/simonpj/papers/papers.html\" target=\"_blank\" rel=\"external\">http://research.microsoft.com/en-us/um/people/simonpj/papers/papers.html</a><ul>\n<li>SPJ大神的主页，Haskell的创造者之一（Wadler也是），理论和码功都是大神级的。</li>\n</ul>\n</li>\n<li><a href=\"http://dotat.at/tmp/danvy-filinski-mscs92.pdf\" target=\"_blank\" rel=\"external\">http://dotat.at/tmp/danvy-filinski-mscs92.pdf</a><ul>\n<li>一篇关于CPS的论文，CPS算是一种古老的黑科技，Lisp, Haskell, JS, Scala, C++里面都有，但是个人觉得Lisp和Haskell用得最优雅。</li>\n</ul>\n</li>\n<li><em>The Little Schemer</em><ul>\n<li>王垠在印第安纳的老板写的scheme的书，介绍了CPS和Y Combinator，学Haskell可以参考。</li>\n</ul>\n</li>\n<li>Idris <ul>\n<li><a href=\"http://www.idris-lang.org/\" target=\"_blank\" rel=\"external\">http://www.idris-lang.org/</a></li>\n<li>一个通用的依赖类型的函数式编程语言，可以看做升级版的Haskell。</li>\n</ul>\n</li>\n<li>Coq<ul>\n<li><a href=\"https://coq.inria.fr/\" target=\"_blank\" rel=\"external\">https://coq.inria.fr/</a></li>\n<li>一个用来定理证明的依赖类型的函数式编程语言。</li>\n<li><em><a href=\"https://www.cis.upenn.edu/~bcpierce/sf/current/index.html\" target=\"_blank\" rel=\"external\">Software Foundations</a></em>，programming language领域很著名的书，没看过也要知道名字=w=</li>\n</ul>\n</li>\n</ul>\n<h2 id=\"编辑器\"><a href=\"#编辑器\" class=\"headerlink\" title=\"编辑器\"></a>编辑器</h2><ul>\n<li>Emacs: Haskell mode</li>\n<li>Spacemacs: Haskell Layer （我目前用的，基于Emacs的Haskell mode）</li>\n<li>Vim: Haskell mode</li>\n<li>Intellij: Haskell plugin</li>\n</ul>\n<p>推荐Emacs，Vim没用过，但Emacs的Haskell mode比Vim的出名很多（带有bias），所以Emacs写Haskell应该更方便。IntelliJ不够智能，快捷键不好用，对cabal和stackage集成效果也不如Emacs。<em>（前几年的情况，现在不知道了）</em></p>\n<h2 id=\"Haskell安装\"><a href=\"#Haskell安装\" class=\"headerlink\" title=\"Haskell安装\"></a>Haskell安装</h2><ul>\n<li>推荐使用Haskell官网的Haskell Platform。</li>\n</ul>\n<p><em>注：这个好像过时了，现在比较流行用stackage，毕竟cabal hell太讨厌了。</em></p>\n","excerpt":"","more":"<p>这个是我前些年自学Haskell时整理的资料，现在可能有点过时了，不过应该还有些参考价值吧。</p>\n<h2 id=\"入门参考\"><a href=\"#入门参考\" class=\"headerlink\" title=\"入门参考\"></a>入门参考</h2><ul>\n<li>参考 <a href=\"http://stackoverflow.com/questions/1012573/getting-started-with-haskell\">http://stackoverflow.com/questions/1012573/getting-started-with-haskell</a><ul>\n<li>先看<em>LYAH</em>，看到Functor时可以开始做<em>haskell 99 problems</em>。不用全做完，做到差不多有感觉了开始看LYAH的Functor, Applicative和Monad。</li>\n<li>看<em>RWH</em>的Monad部分，看得懂就多看几章，看不懂就先放着。</li>\n<li>接着可以刷 <a href=\"https://wiki.haskell.org/Tutorials#Using_monads\">https://wiki.haskell.org/Tutorials#Using_monads</a> 这个页面里Monad的一些paper和文章。<ul>\n<li><em>How to build a monadic interpreter in one day</em>: 挺好的文章，写一个迷你的解释器，可看可不看，建议不看而去看Philip Wadler的两篇Monad的论文。</li>\n<li><em>Monad Transformers Explained</em>, <em>MonadCont under the hood</em>: 这两篇讲的是MT和CPS，建议弄懂Monad后再挑战这种更蛋疼的概念。</li>\n<li><em>IO inside</em>: 是讲IO Monad的，这种Monad比较简单，文章写得很好。</li>\n<li><em>The Haskell Programmer’s Guide to the IO Monad - Don’t Panic</em>: 没看，讲范畴论（category theory）的，不做研究不需要了解，建议等想深入了再学。</li>\n<li><em>Systematic Design of Monads</em>: 没看，不过看上去挺有趣的。</li>\n<li><em>All About Monads</em>: 可以看一部分，有些内容比较难，那些东西晚点看。</li>\n<li>还有一些文章我也没接触，大家可以挑自己感兴趣的看看。</li>\n</ul>\n</li>\n<li>和上面可以同时进行的是刷<a href=\"http://homepages.inf.ed.ac.uk/wadler/\">Philip Wadler</a>关于Monad的论文，推荐<em>Monads for functional programming</em>和<em>The essence of functional programming</em>。</li>\n<li>感觉对Monad有一些掌握后可以尝试用Haskell写一个Lisp的解释器 <a href=\"https://en.wikibooks.org/wiki/Write_Yourself_a_Scheme_in_48_Hours\">https://en.wikibooks.org/wiki/Write_Yourself_a_Scheme_in_48_Hours</a> </li>\n</ul>\n</li>\n<li>接下来可以看看Penn的<em>CIS194</em>，这门课每年的在Monad之后讲的内容不一样，包括一些并发、GUI和类型推导理论里的最前沿的内容。可以看看然后做做里面的作业。</li>\n<li>接着可以开始做<em><a href=\"https://github.com/NICTA/course\">NICTA course</a></em>，非常好的Haskell进阶课程，形式也很有意思。<strong>（强烈推荐这个课程，里面的代码一定要尽量写完，非常有意思）</strong></li>\n<li>这个阶段后看自己的兴趣选择喜欢的东西学学。</li>\n</ul>\n<h2 id=\"资料汇总\"><a href=\"#资料汇总\" class=\"headerlink\" title=\"资料汇总\"></a>资料汇总</h2><ul>\n<li><a href=\"https://en.wikibooks.org/wiki/Haskell\">https://en.wikibooks.org/wiki/Haskell</a><ul>\n<li>很重要的参考资料，遇到不懂的概念都可以去看看</li>\n</ul>\n</li>\n<li><a href=\"https://www.haskell.org/onlinereport/haskell2010/\">https://www.haskell.org/onlinereport/haskell2010/</a><ul>\n<li>语言标准</li>\n</ul>\n</li>\n<li>Hoogle: <a href=\"https://www.haskell.org/hoogle/\">https://www.haskell.org/hoogle/</a><ul>\n<li>查Package和Package源代码的地方，Haskell的代码写得都非常漂亮，流行Package的作者又全是大神，没事可以多看看他们的代码。</li>\n</ul>\n</li>\n<li>Stackage: <a href=\"https://www.stackage.org/\">https://www.stackage.org/</a><ul>\n<li>另一个查Package和源代码的地方，我记得这边有时能查到一些Hoogle查不到的Package。</li>\n</ul>\n</li>\n<li><a href=\"https://wiki.haskell.org/Typeclassopedia\">https://wiki.haskell.org/Typeclassopedia</a><ul>\n<li>介绍了各种Type，写得非常好，推荐。</li>\n</ul>\n</li>\n<li><a href=\"http://www.seas.upenn.edu/~cis194/resources.html\">http://www.seas.upenn.edu/~cis194/resources.html</a><ul>\n<li>很多有用的资料。</li>\n</ul>\n</li>\n<li><a href=\"http://stackoverflow.com/questions/1012573/getting-started-with-haskell\">http://stackoverflow.com/questions/1012573/getting-started-with-haskell</a><ul>\n<li>不全，但给了些学习的路线图。</li>\n</ul>\n</li>\n<li><a href=\"http://www.zhihu.com/topic/19593103\">http://www.zhihu.com/topic/19593103</a><ul>\n<li>知乎的Haskell页面，挺多好的中文资料，但装逼犯（比如轮子）比较多。</li>\n<li><a href=\"http://www.zhihu.com/question/20193745/answer/37300535\">http://www.zhihu.com/question/20193745/answer/37300535</a> 推荐这个帖子</li>\n</ul>\n</li>\n<li><a href=\"http://www.scs.stanford.edu/14sp-cs240h/\">http://www.scs.stanford.edu/14sp-cs240h/</a><ul>\n<li>S大的Haskell课程，偏工程，讲课的两位都是大神，助教也是大神。</li>\n</ul>\n</li>\n<li><a href=\"http://courses.cms.caltech.edu/cs11/material/haskell/\">http://courses.cms.caltech.edu/cs11/material/haskell/</a><ul>\n<li>加州理工的Haskell课程，比较老了，一些资料不错。</li>\n</ul>\n</li>\n<li><a href=\"https://wiki.haskell.org/Learning_Haskell\">https://wiki.haskell.org/Learning_Haskell</a> 和 <a href=\"https://wiki.haskell.org/Tutorials\">https://wiki.haskell.org/Tutorials</a><ul>\n<li>官方的资料收集页面，很多好东西，可以玩一年。</li>\n</ul>\n</li>\n<li><a href=\"http://research.microsoft.com/en-us/um/people/simonpj/papers/papers.html\">http://research.microsoft.com/en-us/um/people/simonpj/papers/papers.html</a><ul>\n<li>SPJ大神的主页，Haskell的创造者之一（Wadler也是），理论和码功都是大神级的。</li>\n</ul>\n</li>\n<li><a href=\"http://dotat.at/tmp/danvy-filinski-mscs92.pdf\">http://dotat.at/tmp/danvy-filinski-mscs92.pdf</a><ul>\n<li>一篇关于CPS的论文，CPS算是一种古老的黑科技，Lisp, Haskell, JS, Scala, C++里面都有，但是个人觉得Lisp和Haskell用得最优雅。</li>\n</ul>\n</li>\n<li><em>The Little Schemer</em><ul>\n<li>王垠在印第安纳的老板写的scheme的书，介绍了CPS和Y Combinator，学Haskell可以参考。</li>\n</ul>\n</li>\n<li>Idris <ul>\n<li><a href=\"http://www.idris-lang.org/\">http://www.idris-lang.org/</a></li>\n<li>一个通用的依赖类型的函数式编程语言，可以看做升级版的Haskell。</li>\n</ul>\n</li>\n<li>Coq<ul>\n<li><a href=\"https://coq.inria.fr/\">https://coq.inria.fr/</a></li>\n<li>一个用来定理证明的依赖类型的函数式编程语言。</li>\n<li><em><a href=\"https://www.cis.upenn.edu/~bcpierce/sf/current/index.html\">Software Foundations</a></em>，programming language领域很著名的书，没看过也要知道名字=w=</li>\n</ul>\n</li>\n</ul>\n<h2 id=\"编辑器\"><a href=\"#编辑器\" class=\"headerlink\" title=\"编辑器\"></a>编辑器</h2><ul>\n<li>Emacs: Haskell mode</li>\n<li>Spacemacs: Haskell Layer （我目前用的，基于Emacs的Haskell mode）</li>\n<li>Vim: Haskell mode</li>\n<li>Intellij: Haskell plugin</li>\n</ul>\n<p>推荐Emacs，Vim没用过，但Emacs的Haskell mode比Vim的出名很多（带有bias），所以Emacs写Haskell应该更方便。IntelliJ不够智能，快捷键不好用，对cabal和stackage集成效果也不如Emacs。<em>（前几年的情况，现在不知道了）</em></p>\n<h2 id=\"Haskell安装\"><a href=\"#Haskell安装\" class=\"headerlink\" title=\"Haskell安装\"></a>Haskell安装</h2><ul>\n<li>推荐使用Haskell官网的Haskell Platform。</li>\n</ul>\n<p><em>注：这个好像过时了，现在比较流行用stackage，毕竟cabal hell太讨厌了。</em></p>\n"},{"title":"ipfs","date":"2017-08-07T16:19:53.000Z","_content":"","source":"_posts/ipfs.md","raw":"---\ntitle: ipfs\ndate: 2017-08-08 00:19:53\ntags:\n---\n","slug":"ipfs","published":1,"updated":"2017-08-07T16:19:53.428Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cj62dj3ld000320tpm9fh7lpm","content":"","excerpt":"","more":""},{"title":"Hello World","date":"2016-09-22T15:50:21.000Z","_content":"\n重新开坑写博客。\n\n不知道这次能坚持多久.w.\n","source":"_posts/Hello-World.md","raw":"---\ntitle: Hello World\ndate: 2016-09-22 23:50:21\ntags:\n---\n\n重新开坑写博客。\n\n不知道这次能坚持多久.w.\n","slug":"Hello-World","published":1,"updated":"2017-08-07T16:03:06.839Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cj62dj3lr000520tp6ii30noi","content":"<p>重新开坑写博客。</p>\n<p>不知道这次能坚持多久.w.</p>\n","excerpt":"","more":"<p>重新开坑写博客。</p>\n<p>不知道这次能坚持多久.w.</p>\n"}],"PostAsset":[],"PostCategory":[],"PostTag":[{"post_id":"cj62dj3l0000120tp6es2mngm","tag_id":"cj62dj3lh000420tp4b94i4tn","_id":"cj62dj3lv000620tpgkxlm6vo"}],"Tag":[{"name":"Programming","_id":"cj62dj3lh000420tp4b94i4tn"}]}}